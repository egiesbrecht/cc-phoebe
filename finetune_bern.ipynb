{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/pushshift/cc-phoebe/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import math\n",
    "import datasets\n",
    "from datasets import DatasetDict, load_dataset, Dataset\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import AdamW\n",
    "from torch import nn\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    T5Tokenizer,\n",
    "    T5ForSequenceClassification,\n",
    "    T5Config,\n",
    "    BertTokenizer, \n",
    "    RobertaTokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from load_set import *\n",
    "from epoch_stats import EpochStats#, print_stat_tuples\n",
    "import model_training\n",
    "from model_training import (\n",
    "    BatchBuffer, \n",
    "    train_bern_model, \n",
    "    mask_tokens, \n",
    "    preprocess_with_given_labels, \n",
    "    num_parameters, \n",
    "    num_trainable_parameters, \n",
    "    preprocess_for_causallm, \n",
    "    preprocess_for_multiple_choice,\n",
    "    preprocess_for_seq2seq_swag\n",
    ")\n",
    "import bert_i1_1_modeling as bert_i1_1\n",
    "import coin_i2C_modeling as ci2C\n",
    "import coin_i2D_modeling as ci2D\n",
    "import coin_i3A_modeling as ci3A\n",
    "import coin_i3B_modeling as ci3B\n",
    "import coin_i3C_modeling as ci3C\n",
    "import rnn_modeling as ci_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_FILE = 1\n",
    "TRAIN_BATCH_SIZE = 2\n",
    "TEST_BATCH_SIZE = 2\n",
    "CHECKPOINT_PATH = None #\"hyp_cls/bert-base-uncased_main-label/\" # datetime.datetime.now().strftime(\"tmp_models/rann_sffn/run_part_load_%Y-%m-%d_%H:%M:%S\")\n",
    "USE_CUSTOM_DATALOADER = True\n",
    "SHUFFLE_CUSTOM_DATALOADER = True\n",
    "LEARNING_RATE = 1e-5\n",
    "EPS = 1e-8\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 30_522\n",
    "#VOCAB_SIZE = 32_000\n",
    "#VOCAB_SIZE = 52_000\n",
    "MAX_POSITION_EMBEDDINGS = 512#24**2\n",
    "HIDDEN_SIZE = 1024\n",
    "IS_HF_MODEL = False\n",
    "GENERIC_OUTPUT_CLASS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALWAYS CHECK num_labels, RFFN doesn't throw an error on a wrong parameter\n",
    "rffn_base_model_path = \"tmp_models/COIN-i3C_mcca-translation-en-de_0029-500k_1x2_1dec-none_no-revert_chunkwise_group-exp_congen-head_B10_multi-query-2_switch-ii_mpe576_no-cross-att/\"\n",
    "#rffn_base_model_path = \"tmp_models/COIN-i2B_oasst1_25k_1x3_000dec_none-decoder-revert-out_chunkwise_nt-case-3_2-decay-parts_allow-enc-tf/\"\n",
    "#rffn_base_model_path = \"tmp_models/RRB_oasst1_25k_2-2-encoder_0-1-decoder_decay_maskedLM.15_.2share_docx1_wtf/\"\n",
    "#rffn_tokenizer_path = \"pretrained_models/rffn_wikitext_516_tokenizer\"\n",
    "rffn_tokenizer_path = rffn_base_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default, sst2, swag, uni-main-hyp, uni-side-hyp, bucket-sort, duplicate-string, parity-check\n",
    "TEST_METHOD = \"uni-side-hyp\"\n",
    "ILOC_LIMIT = None\n",
    "DEFAULT_TEACHER_FORCING = False\n",
    "DOC_PAD_TOKENS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_METHOD == \"default\":\n",
    "    NUM_LABELS = 7\n",
    "elif TEST_METHOD in (\"parity-check\", \"sst2\"):\n",
    "    NUM_LABELS = 2\n",
    "elif TEST_METHOD == \"swag\":\n",
    "    NUM_LABELS = 4\n",
    "elif TEST_METHOD == \"uni-main-hyp\":\n",
    "    NUM_LABELS = 10\n",
    "elif TEST_METHOD == \"uni-side-hyp\":\n",
    "    NUM_LABELS = 20\n",
    "else:\n",
    "    NUM_LABELS = 2\n",
    "\n",
    "TEST_SST2 = TEST_METHOD == \"sst2\"\n",
    "ONE_LABEL_ONLY = TEST_SST2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_METHOD == \"parity-check\":\n",
    "    VOCAB_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    model = ci_rnn.COINForSequenceClassification(\n",
    "        config=ci_rnn.RNNConfig(\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "            hidden_dropout_prob=0.1,\n",
    "            num_hidden_layers=2,\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            intermediate_size=HIDDEN_SIZE,\n",
    "            num_labels=NUM_LABELS,\n",
    "            layer_norm_eps=1e-12,\n",
    "            rope_dim=16,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenConfig:\n",
    "    def __init__(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    ONE_LABEL_ONLY = True\n",
    "    tokenizer = None\n",
    "    class ParityLSTM(nn.Module):\n",
    "        def __init__(self, hidden_size=HIDDEN_SIZE):\n",
    "            super().__init__()\n",
    "            self.config = None\n",
    "            self.hidden_size = hidden_size\n",
    "            self.lstm = nn.LSTM(1, hidden_size, batch_first=True)\n",
    "            self.L1 = nn.Linear(hidden_size, 128)\n",
    "            self.L2 = nn.Linear(128, 2)\n",
    "        \n",
    "        def forward(self, X):\n",
    "            N = len()\n",
    "\n",
    "            y = F.relu(self.L1(l_out))\n",
    "            y = F.dropout(y, 0.5)\n",
    "            y = self.L2(y)\n",
    "            y = F.sigmoid(y)\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    ONE_LABEL_ONLY = True\n",
    "    tokenizer = None\n",
    "    class LSTMForParityCheck(nn.Module):\n",
    "        def __init__(self, config):\n",
    "            super().__init__()\n",
    "            self.config = config\n",
    "            self.embeddings = nn.Linear(config.vocab_size, config.hidden_size)\n",
    "            self.n_layers = config.num_hidden_layers\n",
    "            self.lstm = nn.LSTM(2, config.hidden_size, batch_first=True, num_layers=self.n_layers, dropout=config.hidden_dropout_prob)\n",
    "            self.pooler = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "            self.classifier = nn.Sequential(\n",
    "                #nn.Dropout(config.hidden_dropout_prob, \n",
    "                nn.Linear(config.hidden_size, config.num_labels)\n",
    "            )\n",
    "            self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        def forward(self, input_ids, attention_mask=None, labels=None, **kwargs):\n",
    "            logits = F.one_hot(input_ids.long(), self.config.vocab_size).float()\n",
    "            #logits = self.embeddings(logits)\n",
    "            B, T, C = logits.shape\n",
    "            hidden = (torch.randn(self.n_layers, B, C, device=logits.device), torch.randn(self.n_layers, B, C, device=logits.device))\n",
    "            #logits, hidden = self.lstm(logits, hidden)\n",
    "            logits, hidden = self.lstm(logits)\n",
    "            #for i in range(T):\n",
    "            #    out, hidden = self.lstm(logits[:, i:i+1, :], hidden)\n",
    "            #r_logits = self.pooler(logits[:, -1, :])\n",
    "            #r_logits = F.tanh(logits)\n",
    "            #r_logits = out[:, -1]\n",
    "            #print(logits.shape, logits.view(T, -1).shape)\n",
    "            r_logits = self.classifier(logits[:, -1])\n",
    "            #r_logits = F.log_softmax(r_logits, 1)\n",
    "            loss = self.loss_fn(r_logits, labels)\n",
    "            return ci3C.COINOutputClass(\n",
    "                logits=r_logits,\n",
    "                loss=loss\n",
    "            )\n",
    "\n",
    "    model = LSTMForParityCheck(\n",
    "        config=GenConfig(\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "            hidden_dropout_prob=0.5,\n",
    "            num_hidden_layers=1,\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            num_labels=NUM_LABELS,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    IS_HF_MODEL = False\n",
    "    ONE_LABEL_ONLY = True\n",
    "    tokenizer = None\n",
    "    class BertForParityCheck(nn.Module):\n",
    "        def __init__(self, config):\n",
    "            super().__init__()\n",
    "            self.config = config\n",
    "            #self.bert = transformers.BertModel(config)\n",
    "            self.bert = transformers.BertForSequenceClassification(config)\n",
    "            self.embeddings = nn.Linear(config.vocab_size, config.hidden_size)\n",
    "            self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        def forward(self, input_ids, attention_mask=None, labels=None, **kwargs):\n",
    "            emb = self.embeddings(F.one_hot(input_ids, self.config.vocab_size).float())\n",
    "            B, T, C = emb.shape\n",
    "            logits = self.bert(inputs_embeds=emb, attention_mask=attention_mask).logits\n",
    "            loss = self.loss_fn(logits, labels)\n",
    "            return ci3C.COINOutputClass(\n",
    "                logits=logits,\n",
    "                loss=loss\n",
    "            )\n",
    "\n",
    "\n",
    "    model = BertForParityCheck(\n",
    "        config=transformers.BertConfig(\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "            num_hidden_layers=5,\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            num_attention_heads=1,\n",
    "            num_labels=NUM_LABELS,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    IS_HF_MODEL = True\n",
    "    ONE_LABEL_ONLY = True\n",
    "    tokenizer = None\n",
    "    class BertForBucketSort(nn.Module):\n",
    "        def __init__(self, config):\n",
    "            super().__init__()\n",
    "            self.config = config\n",
    "            self.bert = transformers.BertModel(config)\n",
    "            self.embeddings = nn.Linear(config.vocab_size, config.hidden_size)\n",
    "            self.lm_head = nn.Linear(config.hidden_size, config.vocab_size, bias=False)\n",
    "            self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        def forward(self, input_ids, attention_mask=None, labels=None, **kwargs):\n",
    "            emb = self.embeddings(F.one_hot(input_ids, self.config.vocab_size).float())\n",
    "            B, T, C = emb.shape\n",
    "            logits = self.bert(inputs_embeds=emb, attention_mask=attention_mask).last_hidden_state\n",
    "            logits = self.lm_head(logits)\n",
    "            loss = self.loss_fn(logits.view(-1, logits.shape[-1]), labels.view(-1))\n",
    "            return ci3C.COINOutputClass(\n",
    "                logits=logits,\n",
    "                loss=loss\n",
    "            )\n",
    "\n",
    "\n",
    "    model = BertForBucketSort(\n",
    "        config=transformers.BertConfig(\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "            num_hidden_layers=5,\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            num_attention_heads=1,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci3C_CONFIG = ci3C.COINConfig(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_labels=NUM_LABELS,\n",
    "    forward_method=\"parallel\",\n",
    "    apply_decay=False,\n",
    "    num_decay_parts=1,\n",
    "    hidden_retention_act=\"relu\",\n",
    "    hidden_pos_offset=False,\n",
    "    rope_dim=16,\n",
    "    num_query_heads=1,\n",
    "\n",
    "    decoder_output=\"none\",\n",
    "    revert_decoder=False,\n",
    "    decoder_schema=[0] * 6,\n",
    "    cross_encoder_schema=[0] * 6,\n",
    "    experts_schema=None,#[2, 2],\n",
    "    block_io_schema=None,#[[1024, 1024*4, 1024]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    tokenizer = None\n",
    "    ONE_LABEL_ONLY = True\n",
    "    model = ci3C.COINForParityCheck(\n",
    "        config=ci3C_CONFIG\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    ONE_LABEL_ONLY = True\n",
    "    tokenizer = None\n",
    "    model = ci3C.COINForBucketSort(\n",
    "        config=ci3C_CONFIG\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    model = ci3C.COINForSequenceClassification(\n",
    "        config=ci3C_CONFIG\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num layers: 6\n",
      "gamma schema: [0.96875, 0.9820516109466553, 0.9896913170814514, 0.9940792322158813, 0.9965994358062744, 0.998046875]\n",
      "layer 0 num experts: 1\n",
      "layer 1 num experts: 1\n",
      "layer 2 num experts: 1\n",
      "layer 3 num experts: 1\n",
      "layer 4 num experts: 1\n",
      "layer 5 num experts: 1\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    model = ci3C.COINForHierachicalClassification(\n",
    "        config=ci3C_CONFIG\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    N_ITER = 4\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    #tokenizer = RobertaTokenizer.from_pretrained(f\"{rffn_base_model_path}/bpe_tokenizer/\")\n",
    "    model = ci3C.COINForSequenceClassification.from_pretrained(\n",
    "        f\"{rffn_base_model_path}/model/epoch_{N_ITER}/model\",\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "        num_labels=NUM_LABELS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    model = ci3B.COINForSequenceClassification(\n",
    "        config=ci3B.COINConfig(\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "            num_labels=NUM_LABELS,\n",
    "            forward_method=\"parallel\",\n",
    "            apply_decay=False,\n",
    "            num_decay_parts=1,\n",
    "            hidden_retention_act=\"relu\",\n",
    "\n",
    "            decoder_output=\"strict\",\n",
    "            decoder_schema=[0, 1],\n",
    "            cross_encoder_schema=[0, 0],\n",
    "            experts_schema=None,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    model = ci3A.COINForSequenceClassification(\n",
    "        config=ci3A.COINConfig(\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "            num_labels=NUM_LABELS,\n",
    "            forward_method=\"parallel\",\n",
    "            apply_decay=False,\n",
    "            num_decay_parts=1,\n",
    "            hidden_retention_act=\"relu\",\n",
    "            apply_hidden_pos_offset=False,\n",
    "            #fuzed_decay_attention_mask=False,\n",
    "\n",
    "            decoder_output=\"none\",\n",
    "            revert_decoder=False,\n",
    "            decoder_schema=[1, 1],\n",
    "            cross_encoder_schema=[0] * 2,\n",
    "            experts_schema=None,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    N_ITER = 0\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    #tokenizer = RobertaTokenizer.from_pretrained(f\"{rffn_base_model_path}/bpe_tokenizer/\")\n",
    "    model = ci3A.COINForSequenceClassification.from_pretrained(\n",
    "        f\"{rffn_base_model_path}/model/epoch_{N_ITER}/model\",\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "        num_labels=NUM_LABELS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    #tokenizer = RobertaTokenizer.from_pretrained(f\"{rffn_base_model_path}/bpe_tokenizer/\")\n",
    "    NUM_REGIONS = 1\n",
    "    model = ci2D.COINForSequenceClassification(\n",
    "        config=ci2D.COINConfig(\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "            num_labels=NUM_LABELS,\n",
    "            hidden_retention_act=\"relu\",\n",
    "            #hidden_out_act=None,\n",
    "            forward_method=\"parallel\",\n",
    "            apply_decay=False,\n",
    "            reverse_decay=False,\n",
    "            num_decay_parts=1,\n",
    "            decoder_output=\"strict\",\n",
    "            #rope_dim=16,\n",
    "            \n",
    "            num_regions=NUM_REGIONS,\n",
    "            decoder_schema=      [0, 1],\n",
    "            cross_encoder_schema=[0, 0],\n",
    "            \n",
    "            share_S=False,\n",
    "            \n",
    "            #layer_norm_eps=1e-12,\n",
    "            #retention_group_norm_eps=1e-8,\n",
    "            #rms_norm_eps=1e-12,\n",
    "\n",
    "            disable_teacher_forcing=False,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    N_ITER = 0\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    #tokenizer = RobertaTokenizer.from_pretrained(f\"{rffn_base_model_path}/bpe_tokenizer/\")\n",
    "    model = ci2D.COINForSequenceClassification.from_pretrained(\n",
    "        f\"{rffn_base_model_path}/model/epoch_{N_ITER}/model\",\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "        num_labels=NUM_LABELS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    #tokenizer = RobertaTokenizer.from_pretrained(f\"{rffn_base_model_path}/bpe_tokenizer/\")\n",
    "    NUM_REGIONS = 1\n",
    "    model = ci2C.COINForSequenceClassification(\n",
    "        config=ci2C.COINConfig(\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "            num_labels=NUM_LABELS,\n",
    "            hidden_retention_act=\"relu\",\n",
    "            #hidden_out_act=None,\n",
    "            forward_method=\"parallel\",\n",
    "            apply_decay=False,\n",
    "            #fixed_decay_value=None,\n",
    "            num_decay_parts=1,\n",
    "            #reverse_decay=False,\n",
    "            chunkwise_num_chunks=4,\n",
    "            apply_chunking_globally=False,\n",
    "            #apply_hidden_pos_offset=False,\n",
    "            decoder_output=\"none\",\n",
    "            \n",
    "            num_regions=NUM_REGIONS,\n",
    "            decoder_schema=      [0],\n",
    "            cross_encoder_schema=[0],\n",
    "            multi_head_qkv=False,\n",
    "            num_heads=16,\n",
    "            share_S=False,\n",
    "            #num_repetitions=1,\n",
    "            add_residual_query_skip=False,\n",
    "\n",
    "            #layer_norm_eps=1e-12,\n",
    "            #retention_group_norm_eps=1e-8,\n",
    "            #rms_norm_eps=1e-12,\n",
    "\n",
    "            print_checks=CHECK_RUN,\n",
    "            reset_S_n_state=False,\n",
    "            disable_teacher_forcing=False,\n",
    "\n",
    "            apply_selective_attention_params=False,\n",
    "            #selective_param_Ns=(2, 2),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    N_ITER = 0\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    #tokenizer = RobertaTokenizer.from_pretrained(f\"{rffn_base_model_path}/bpe_tokenizer/\")\n",
    "    model = ci2C.COINForSequenceClassification.from_pretrained(\n",
    "        f\"{rffn_base_model_path}/model/epoch_{N_ITER}/model\",\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "        num_labels=NUM_LABELS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "    class MambaOutput:\n",
    "        def __init__(self, out):\n",
    "            self.logits = out\n",
    "            self.encoder_hidden_state = None\n",
    "            self.S = None\n",
    "            self.C = None\n",
    "            self.loss = None\n",
    "            self.aux_loss = None\n",
    "\n",
    "    class MambaForSequenceClassification(nn.Module):\n",
    "        def __init__(self, path, **kwargs):\n",
    "            super().__init__()\n",
    "            self.mamba = transformers.MambaModel.from_pretrained(path, num_hidden_layers=12, **kwargs)\n",
    "            self.config = self.mamba.config\n",
    "            self.dense = nn.Linear(768, 768)\n",
    "            self.act = nn.Tanh()\n",
    "            self.cls = nn.Linear(768, NUM_LABELS)\n",
    "\n",
    "        def forward(self, **kwargs):\n",
    "            logits = self.mamba(**kwargs).last_hidden_state\n",
    "            out = self.act(self.dense(logits[:, 0, :]))\n",
    "            out = self.cls(out)\n",
    "            return MambaOutput(out)\n",
    "\n",
    "        \n",
    "    #model = transformers.MambaModel.from_pretrained(\"state-spaces/mamba-130m-hf\", num_labels=NUM_LABELS)\n",
    "    model = MambaForSequenceClassification(\"state-spaces/mamba-130m-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    IS_HF_MODEL = True\n",
    "    tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    model = transformers.BertForSequenceClassification.from_pretrained(\n",
    "        \"bert-base-uncased\",\n",
    "        num_labels=NUM_LABELS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    IS_HF_MODEL = True\n",
    "    tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    #tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    model = transformers.BertForSequenceClassification(\n",
    "        config=transformers.BertConfig(\n",
    "            num_labels=NUM_LABELS,\n",
    "            #num_hidden_layers=2,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116,884,548\n",
      "116,884,500\n"
     ]
    }
   ],
   "source": [
    "print(\"{:,}\\n{:,}\".format(num_parameters(model), num_trainable_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ds_path = \"../datasets/big_AAABDON_Nmax_st200_s0_a10_tvsplit.1_no_norm/\"\n",
    "\n",
    "train_ds = [\n",
    "    f\"{base_ds_path}/train/train_00[0-{TO_FILE}].csv\"\n",
    "\n",
    "    #f\"datasets/big_AAABDON_Nmax_st200_s0_a10_tvsplit.1_no_norm/train/train_00[0-9].csv\",\n",
    "    #f\"datasets/big_AAABDON_Nmax_st200_s0_a10_tvsplit.1_no_norm/train/train_01[0-9].csv\"\n",
    "]\n",
    "test_ds = [\n",
    "    f\"{base_ds_path}/validation/validation_00[0-{TO_FILE}].csv\"\n",
    "\n",
    "    #f\"datasets/big_AAABDON_Nmax_st200_s0_a10_tvsplit.1_no_norm/validation/validation_00[0-9].csv\",\n",
    "    #f\"datasets/big_AAABDON_Nmax_st200_s0_a10_tvsplit.1_no_norm/validation/validation_01[0-9].csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files\n",
      "    ../uni-hyp-class/wordpiece_abstracts_train_side_label_1.csv\n",
      "loading files\n",
      "    ../uni-hyp-class/wordpiece_abstracts_test_side_label_1.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'a0', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9', 'b0', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9'],\n",
       "        num_rows: 862\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'a0', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9', 'b0', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9'],\n",
       "        num_rows: 92\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if TEST_METHOD == \"sst2\":\n",
    "    dataset = DatasetDict({\n",
    "        \"train\": load_dataset(\"glue\", name=\"sst2\", split=\"train[:10000]\").rename_column(\"sentence\", \"text\"),\n",
    "        \"test\": load_dataset(\"glue\", name=\"sst2\", split=\"validation\").rename_column(\"sentence\", \"text\")\n",
    "    })\n",
    "elif TEST_METHOD == \"default\":\n",
    "    dataset = DatasetDict({\n",
    "        \"train\": load_set(train_ds, unused_fields=[\"author\", \"subreddit\", \"style\"], iloc_limit=ILOC_LIMIT),\n",
    "        \"test\":  load_set(test_ds, unused_fields=[\"author\", \"subreddit\", \"style\"], iloc_limit=ILOC_LIMIT)\n",
    "\n",
    "        #\"train\": load_dataset(\"glue\", name=\"mnli\", split=\"train[0:10000]\"),\n",
    "        #\"test\": load_dataset(\"glue\", name=\"mnli\", split=\"validation_matched[0:1500]\")\n",
    "\n",
    "        #\"train\": load_dataset(\"squad_v2\", split=\"train[0:10000]\"),\n",
    "        #\"test\": load_dataset(\"squad_v2\", split=\"test[0:1500]\")\n",
    "    })\n",
    "elif TEST_METHOD == \"swag\":\n",
    "    dataset = DatasetDict({\n",
    "        \"train\": load_dataset(\"Rowan/hellaswag\", split=\"train\"),\n",
    "        \"test\": load_dataset(\"Rowan/hellaswag\", split=\"validation\")\n",
    "    })\n",
    "elif TEST_METHOD in (\"uni-main-hyp\", \"uni-side-hyp\"):\n",
    "    if TEST_METHOD == \"uni-main-hyp\":\n",
    "        DS_TRAIN_PATH = \"../uni-hyp-class/wordpiece_abstracts_train.csv\"\n",
    "        DS_TEST_PATH = \"../uni-hyp-class/wordpiece_abstracts_test.csv\"\n",
    "    elif TEST_METHOD == \"uni-side-hyp\":\n",
    "        DS_TRAIN_PATH = \"../uni-hyp-class/wordpiece_abstracts_train_side_label_1.csv\"\n",
    "        DS_TEST_PATH = \"../uni-hyp-class/wordpiece_abstracts_test_side_label_1.csv\"\n",
    "    dataset = DatasetDict({\n",
    "        \"train\": load_set([DS_TRAIN_PATH], unused_fields=[\"head\", \"body\", \"strlabels\"]),\n",
    "        \"test\": load_set([DS_TEST_PATH], unused_fields=[\"head\", \"body\", \"strlabels\"]),\n",
    "    })\n",
    "elif TEST_METHOD == \"bucket-sort\":\n",
    "    #dataset = generate_bucket_sort_set(B=100, T=MAX_POSITION_EMBEDDINGS, vocab_size=VOCAB_SIZE)\n",
    "    dataset = DatasetDict({\n",
    "        #\"train\": Dataset.from_dict(generate_bucket_sort_set(B=100_000, T=MAX_POSITION_EMBEDDINGS, vocab_size=VOCAB_SIZE)),\n",
    "        #\"test\": Dataset.from_dict(generate_bucket_sort_set(B=1000, T=MAX_POSITION_EMBEDDINGS, vocab_size=VOCAB_SIZE))\n",
    "        \"train\": generate_uniform_batches(generate_bucket_sort_set, B=TRAIN_BATCH_SIZE, T=MAX_POSITION_EMBEDDINGS, vocab_size=VOCAB_SIZE, num_samples=10_000),\n",
    "        \"test\": generate_uniform_batches(generate_bucket_sort_set, B=TEST_BATCH_SIZE, T=MAX_POSITION_EMBEDDINGS, vocab_size=VOCAB_SIZE, num_samples=1000)\n",
    "    })\n",
    "elif TEST_METHOD == \"duplicate-string\":\n",
    "    dataset = DatasetDict({\n",
    "        \"train\": generate_duplicate_string_set(B=100_000, T=MAX_POSITION_EMBEDDINGS, vocab_size=VOCAB_SIZE),\n",
    "        \"test\": generate_duplicate_string_set(B=1000, T=MAX_POSITION_EMBEDDINGS, vocab_size=VOCAB_SIZE)\n",
    "    })\n",
    "elif TEST_METHOD == \"parity-check\":\n",
    "    dataset = DatasetDict({\n",
    "        #\"train\": generate_parity_check_set(B=10_000, T=MAX_POSITION_EMBEDDINGS),\n",
    "        #\"test\": generate_parity_check_set(B=1000, T=MAX_POSITION_EMBEDDINGS)\n",
    "        \"train\": generate_uniform_batches(generate_parity_check_set, B=TRAIN_BATCH_SIZE, T=MAX_POSITION_EMBEDDINGS, vocab_size=VOCAB_SIZE, num_samples=10_000),\n",
    "        \"test\": generate_uniform_batches(generate_parity_check_set, B=TEST_BATCH_SIZE, T=MAX_POSITION_EMBEDDINGS, vocab_size=VOCAB_SIZE, num_samples=1000)\n",
    "    })\n",
    "else:\n",
    "    raise ValueError(TEST_METHOD)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a0': 0, 'a1': 1, 'a2': 2, 'a3': 3, 'a4': 4, 'a5': 5, 'a6': 6, 'a7': 7, 'a8': 8, 'a9': 9, 'b0': 10, 'b1': 11, 'b2': 12, 'b3': 13, 'b4': 14, 'b5': 15, 'b6': 16, 'b7': 17, 'b8': 18, 'b9': 19}\n",
      "{0: 'a0', 1: 'a1', 2: 'a2', 3: 'a3', 4: 'a4', 5: 'a5', 6: 'a6', 7: 'a7', 8: 'a8', 9: 'a9', 10: 'b0', 11: 'b1', 12: 'b2', 13: 'b3', 14: 'b4', 15: 'b5', 16: 'b6', 17: 'b7', 18: 'b8', 19: 'b9'}\n",
      "['a0', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9', 'b0', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9']\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "if ONE_LABEL_ONLY:\n",
    "    #labels = np.unique(train_df[\"label\"]).tolist()\n",
    "    labels = np.unique(dataset[\"train\"][\"label\"]).tolist()\n",
    "else:\n",
    "    labels = [label for label in dataset['train'].features.keys() if label not in [\"text\"]]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "print(label2id)\n",
    "print(id2label)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 862/862 [00:01<00:00, 659.44 examples/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 92/92 [00:00<00:00, 134.24 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels', 'decoder_input_ids'],\n",
       "        num_rows: 862\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels', 'decoder_input_ids'],\n",
       "        num_rows: 92\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "if TEST_METHOD in (\"default\", \"sst2\", \"uni-main-hyp\", \"uni-side-hyp\"):\n",
    "    encoded_dataset = preprocess_with_given_labels(dataset, tokenizer, labels, label2id, MAX_POSITION_EMBEDDINGS, ONE_LABEL_ONLY, remove_columns=dataset[\"train\"].column_names, \n",
    "                                                   default_teacher_forcing=DEFAULT_TEACHER_FORCING, doc_pad_tokens=DOC_PAD_TOKENS)\n",
    "elif TEST_METHOD == \"swag\":\n",
    "    #encoded_dataset = preprocess_for_multiple_choice(dataset, tokenizer, MAX_POSITION_EMBEDDINGS, remove_columns=dataset[\"train\"].column_names, num_proc=4)\n",
    "    encoded_dataset = preprocess_for_seq2seq_swag(dataset, tokenizer, MAX_POSITION_EMBEDDINGS, remove_columns=dataset[\"train\"].column_names, num_proc=4)\n",
    "elif TEST_METHOD in (\"bucket-sort\", \"duplicate-string\", \"parity-check\"):\n",
    "    encoded_dataset = dataset\n",
    "encoded_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids',\n",
       " 'token_type_ids',\n",
       " 'attention_mask',\n",
       " 'labels',\n",
       " 'decoder_input_ids']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "batch_schema = list(encoded_dataset[\"train\"].features.keys())\n",
    "batch_schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if USE_CUSTOM_DATALOADER:\n",
    "    #train_dataloader = create_dataloader(encoded_dataset[\"train\"])\n",
    "    #test_dataloader = create_dataloader(encoded_dataset[\"test\"])\n",
    "    train_dataloader = BatchBuffer(encoded_dataset[\"train\"], TRAIN_BATCH_SIZE)\n",
    "    if SHUFFLE_CUSTOM_DATALOADER:\n",
    "        train_dataloader.shuffle()\n",
    "    test_dataloader = BatchBuffer(encoded_dataset[\"test\"], TEST_BATCH_SIZE)\n",
    "else:\n",
    "    USE_TOKEN_TYPE_IDS = \"token_type_ids\" in encoded_dataset[\"train\"].features\n",
    "    USE_DEC_II = \"decoder_input_ids\" in encoded_dataset[\"train\"].features\n",
    "    # Load input data into tensors\n",
    "    train_input_ids = torch.tensor(encoded_dataset[\"train\"][\"input_ids\"])\n",
    "    if USE_TOKEN_TYPE_IDS:\n",
    "        train_token_type_ids = torch.tensor(encoded_dataset[\"train\"][\"token_type_ids\"])\n",
    "    train_masks = torch.tensor(encoded_dataset[\"train\"][\"attention_mask\"])\n",
    "    train_labels = torch.tensor(encoded_dataset[\"train\"][\"labels\"])\n",
    "    if USE_DEC_II:\n",
    "        train_dec_ii = torch.tensor(encoded_dataset[\"train\"][\"decoder_input_ids\"])\n",
    "\n",
    "    test_input_ids = torch.tensor(encoded_dataset[\"test\"][\"input_ids\"])\n",
    "    if USE_TOKEN_TYPE_IDS:\n",
    "        test_token_type_ids = torch.tensor(encoded_dataset[\"test\"][\"token_type_ids\"])\n",
    "    test_masks = torch.tensor(encoded_dataset[\"test\"][\"attention_mask\"])\n",
    "    test_labels = torch.tensor(encoded_dataset[\"test\"][\"labels\"])\n",
    "    if USE_DEC_II:\n",
    "        test_dec_ii = torch.tensor(encoded_dataset[\"test\"][\"decoder_input_ids\"])\n",
    "\n",
    "    # Create the DataLoader and Sampler for both sets.\n",
    "    if USE_TOKEN_TYPE_IDS:\n",
    "        train_data = TensorDataset(train_input_ids, train_token_type_ids, train_masks, train_labels)\n",
    "    else:\n",
    "        train_data = TensorDataset(train_input_ids, train_masks, train_labels)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, \n",
    "        sampler=train_sampler, \n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "    if USE_TOKEN_TYPE_IDS:\n",
    "        test_data = TensorDataset(test_input_ids, test_token_type_ids, test_masks, test_labels)\n",
    "    else:\n",
    "        test_data = TensorDataset(test_input_ids, test_masks, test_labels)\n",
    "    test_sampler = SequentialSampler(test_data)\n",
    "    test_dataloader = DataLoader(test_data, \n",
    "        sampler=test_sampler, \n",
    "        batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=EPS)\n",
    "\n",
    "total_steps = len(train_dataloader) / TRAIN_BATCH_SIZE * EPOCHS\n",
    "warmup_steps = math.ceil(total_steps * 0.05)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=warmup_steps,\n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "if len(labels) <= 2:\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "else:\n",
    "    loss_function = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCEWithLogitsLoss()\n",
      "2155.0\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "print(loss_function)\n",
    "print(total_steps)\n",
    "print(warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if CHECKPOINT_PATH is not None:\n",
    "    try:\n",
    "        os.mkdir(CHECKPOINT_PATH)\n",
    "    except OSError as err:\n",
    "        print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#len(encoded_dataset[\"train\"][\"input_ids\"]), len(encoded_dataset[\"train\"][\"input_ids\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids',\n",
       " 'token_type_ids',\n",
       " 'attention_mask',\n",
       " 'labels',\n",
       " 'decoder_input_ids']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "batch_schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COINForHierachicalClassification(\n",
       "  (coin): COINModel(\n",
       "    (encoder_embeddings): COINEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder_embeddings): COINEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (residual_embeddings): COINEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (stack): COINStack(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x COINLayer(\n",
       "          (blocks): ModuleList(\n",
       "            (0): COINBlock(\n",
       "              (qkv): SingleHeadQKV(\n",
       "                (rope): RotaryEmbedding()\n",
       "                (xpos): XPOS()\n",
       "                (act): ReLU()\n",
       "                (out_act): ReLU()\n",
       "                (group_norm): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (cope): CoPE()\n",
       "              )\n",
       "              (norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): COINPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (act): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=20, bias=True)\n",
       "  (loss_fn): BCEWithLogitsLoss()\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COINConfig {\n",
       "  \"allow_encoder_teacher_forcing\": false,\n",
       "  \"apply_decay\": true,\n",
       "  \"apply_decoder_heads\": true,\n",
       "  \"apply_ffn\": true,\n",
       "  \"apply_hidden_pos_offset\": false,\n",
       "  \"apply_softmax_gate\": true,\n",
       "  \"block_io_schema\": null,\n",
       "  \"cross_encoder_schema\": [\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0\n",
       "  ],\n",
       "  \"decoder_output\": \"none\",\n",
       "  \"decoder_schema\": [\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0\n",
       "  ],\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"disable_teacher_forcing\": false,\n",
       "  \"experts_schema\": null,\n",
       "  \"ffn_intermediate_factor\": 4,\n",
       "  \"ffn_intermediate_size\": 4096,\n",
       "  \"fixed_decay_value\": null,\n",
       "  \"fixed_ffn_intermediate_size\": false,\n",
       "  \"fixed_intermediate_size\": false,\n",
       "  \"forward_method\": \"parallel\",\n",
       "  \"global_recurrence_check\": false,\n",
       "  \"group_norm_channels\": 1024,\n",
       "  \"group_norm_num\": 32,\n",
       "  \"hidden_act\": \"tanh\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_out_act\": \"relu\",\n",
       "  \"hidden_pos_offset\": false,\n",
       "  \"hidden_retention_act\": \"relu\",\n",
       "  \"hidden_size\": 1024,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\",\n",
       "    \"3\": \"LABEL_3\",\n",
       "    \"4\": \"LABEL_4\",\n",
       "    \"5\": \"LABEL_5\",\n",
       "    \"6\": \"LABEL_6\",\n",
       "    \"7\": \"LABEL_7\",\n",
       "    \"8\": \"LABEL_8\",\n",
       "    \"9\": \"LABEL_9\",\n",
       "    \"10\": \"LABEL_10\",\n",
       "    \"11\": \"LABEL_11\",\n",
       "    \"12\": \"LABEL_12\",\n",
       "    \"13\": \"LABEL_13\",\n",
       "    \"14\": \"LABEL_14\",\n",
       "    \"15\": \"LABEL_15\",\n",
       "    \"16\": \"LABEL_16\",\n",
       "    \"17\": \"LABEL_17\",\n",
       "    \"18\": \"LABEL_18\",\n",
       "    \"19\": \"LABEL_19\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_factor\": 1,\n",
       "  \"intermediate_size\": 1024,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_10\": 10,\n",
       "    \"LABEL_11\": 11,\n",
       "    \"LABEL_12\": 12,\n",
       "    \"LABEL_13\": 13,\n",
       "    \"LABEL_14\": 14,\n",
       "    \"LABEL_15\": 15,\n",
       "    \"LABEL_16\": 16,\n",
       "    \"LABEL_17\": 17,\n",
       "    \"LABEL_18\": 18,\n",
       "    \"LABEL_19\": 19,\n",
       "    \"LABEL_2\": 2,\n",
       "    \"LABEL_3\": 3,\n",
       "    \"LABEL_4\": 4,\n",
       "    \"LABEL_5\": 5,\n",
       "    \"LABEL_6\": 6,\n",
       "    \"LABEL_7\": 7,\n",
       "    \"LABEL_8\": 8,\n",
       "    \"LABEL_9\": 9\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"local_recurrence_check\": false,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"Consecutive Chain-Of-Input Network\",\n",
       "  \"num_decay_parts\": 1,\n",
       "  \"num_global_chunks\": 4,\n",
       "  \"num_heads\": 32,\n",
       "  \"num_hidden_layers\": 2,\n",
       "  \"num_local_chunks\": 4,\n",
       "  \"num_query_heads\": 1,\n",
       "  \"num_regions\": 2,\n",
       "  \"num_repetitions\": 1,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"reset_S_n_state\": false,\n",
       "  \"retention_group_norm_eps\": 1e-05,\n",
       "  \"reverse_decay\": false,\n",
       "  \"revert_decoder\": false,\n",
       "  \"rms_norm_eps\": 1e-08,\n",
       "  \"rope_dim\": 16,\n",
       "  \"share_S\": false,\n",
       "  \"switch_ii_decoder_ii\": false,\n",
       "  \"transformers_version\": \"4.40.1\",\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(threshold=100_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch     8  of    431.    Elapsed:  0:00:01, Remaining:  0:00:53.\n",
      "  Batch    16  of    431.    Elapsed:  0:00:01, Remaining:  0:00:00.\n",
      "  Batch    24  of    431.    Elapsed:  0:00:01, Remaining:  0:00:00.\n",
      "  Batch    32  of    431.    Elapsed:  0:00:02, Remaining:  0:00:00.\n",
      "  Batch    40  of    431.    Elapsed:  0:00:02, Remaining:  0:00:00.\n",
      "  Batch    48  of    431.    Elapsed:  0:00:02, Remaining:  0:00:00.\n",
      "  Batch    56  of    431.    Elapsed:  0:00:03, Remaining:  0:00:00.\n",
      "  Batch    64  of    431.    Elapsed:  0:00:03, Remaining:  0:00:00.\n",
      "  Batch    72  of    431.    Elapsed:  0:00:03, Remaining:  0:00:00.\n",
      "  Batch    80  of    431.    Elapsed:  0:00:04, Remaining:  0:00:00.\n",
      "  Batch    88  of    431.    Elapsed:  0:00:04, Remaining:  0:00:00.\n",
      "  Batch    96  of    431.    Elapsed:  0:00:04, Remaining:  0:00:00.\n",
      "  Batch   104  of    431.    Elapsed:  0:00:05, Remaining:  0:00:00.\n",
      "  Batch   112  of    431.    Elapsed:  0:00:05, Remaining:  0:00:00.\n",
      "  Batch   120  of    431.    Elapsed:  0:00:05, Remaining:  0:00:00.\n",
      "  Batch   128  of    431.    Elapsed:  0:00:06, Remaining:  0:00:00.\n",
      "  Batch   136  of    431.    Elapsed:  0:00:06, Remaining:  0:00:00.\n",
      "  Batch   144  of    431.    Elapsed:  0:00:06, Remaining:  0:00:00.\n",
      "  Batch   152  of    431.    Elapsed:  0:00:07, Remaining:  0:00:00.\n",
      "  Batch   160  of    431.    Elapsed:  0:00:07, Remaining:  0:00:00.\n",
      "  Batch   168  of    431.    Elapsed:  0:00:07, Remaining:  0:00:00.\n",
      "  Batch   176  of    431.    Elapsed:  0:00:08, Remaining:  0:00:00.\n",
      "  Batch   184  of    431.    Elapsed:  0:00:08, Remaining:  0:00:00.\n",
      "  Batch   192  of    431.    Elapsed:  0:00:08, Remaining:  0:00:00.\n",
      "  Batch   200  of    431.    Elapsed:  0:00:09, Remaining:  0:00:00.\n",
      "  Batch   208  of    431.    Elapsed:  0:00:09, Remaining:  0:00:00.\n",
      "  Batch   216  of    431.    Elapsed:  0:00:09, Remaining:  0:00:00.\n",
      "  Batch   224  of    431.    Elapsed:  0:00:10, Remaining:  0:00:00.\n",
      "  Batch   232  of    431.    Elapsed:  0:00:10, Remaining:  0:00:00.\n",
      "  Batch   240  of    431.    Elapsed:  0:00:10, Remaining:  0:00:00.\n",
      "  Batch   248  of    431.    Elapsed:  0:00:11, Remaining:  0:00:00.\n",
      "  Batch   256  of    431.    Elapsed:  0:00:11, Remaining:  0:00:00.\n",
      "  Batch   264  of    431.    Elapsed:  0:00:11, Remaining:  0:00:00.\n",
      "  Batch   272  of    431.    Elapsed:  0:00:12, Remaining:  0:00:00.\n",
      "  Batch   280  of    431.    Elapsed:  0:00:12, Remaining:  0:00:00.\n",
      "  Batch   288  of    431.    Elapsed:  0:00:12, Remaining:  0:00:00.\n",
      "  Batch   296  of    431.    Elapsed:  0:00:13, Remaining:  0:00:00.\n",
      "  Batch   304  of    431.    Elapsed:  0:00:13, Remaining:  0:00:00.\n",
      "  Batch   312  of    431.    Elapsed:  0:00:13, Remaining:  0:00:00.\n",
      "  Batch   320  of    431.    Elapsed:  0:00:14, Remaining:  0:00:00.\n",
      "  Batch   328  of    431.    Elapsed:  0:00:14, Remaining:  0:00:00.\n",
      "  Batch   336  of    431.    Elapsed:  0:00:14, Remaining:  0:00:00.\n",
      "  Batch   344  of    431.    Elapsed:  0:00:15, Remaining:  0:00:00.\n",
      "  Batch   352  of    431.    Elapsed:  0:00:15, Remaining:  0:00:00.\n",
      "  Batch   360  of    431.    Elapsed:  0:00:15, Remaining:  0:00:00.\n",
      "  Batch   368  of    431.    Elapsed:  0:00:16, Remaining:  0:00:00.\n",
      "  Batch   376  of    431.    Elapsed:  0:00:16, Remaining:  0:00:00.\n",
      "  Batch   384  of    431.    Elapsed:  0:00:16, Remaining:  0:00:00.\n",
      "  Batch   392  of    431.    Elapsed:  0:00:17, Remaining:  0:00:00.\n",
      "  Batch   400  of    431.    Elapsed:  0:00:17, Remaining:  0:00:00.\n",
      "  Batch   408  of    431.    Elapsed:  0:00:17, Remaining:  0:00:00.\n",
      "  Batch   416  of    431.    Elapsed:  0:00:18, Remaining:  0:00:00.\n",
      "  Batch   424  of    431.    Elapsed:  0:00:18, Remaining:  0:00:00.\n",
      "\n",
      "  Average training scores:\n",
      "    loss: 0.6910284064762\n",
      "    accuracy: 0.12993039443155452\n",
      "    per class f1: 0.42728212966031975\n",
      "    f1_micro: 0.48349906087725136\n",
      "    f1_macro: 0.7938128383604021\n",
      "    recall_micro: 0.48349906087725136\n",
      "    recall_macro: 0.8776102088167049\n",
      "    precision_micro: 0.48349906087725136\n",
      "    precision_macro: 0.899129930394431\n",
      "  Training epoch took: 0:00:18\n",
      "\n",
      "Running Testing...\n",
      "  Average testing scores:\n",
      "    loss: 0.49975832681293075\n",
      "    accuracy: 0.29347826086956524\n",
      "    per class f1: 0.6242063492063493\n",
      "    f1_micro: 0.6660024154589376\n",
      "    f1_macro: 0.8739130434782608\n",
      "    recall_micro: 0.6660024154589376\n",
      "    recall_macro: 0.9266304347826086\n",
      "    precision_micro: 0.6660024154589376\n",
      "    precision_macro: 0.9326086956521739\n",
      "  Testing took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "\n",
      "Training...\n",
      "  Batch     8  of    431.    Elapsed:  0:00:00, Remaining:  0:00:00.\n",
      "  Batch    16  of    431.    Elapsed:  0:00:01, Remaining:  0:00:00.\n",
      "  Batch    24  of    431.    Elapsed:  0:00:01, Remaining:  0:00:00.\n",
      "  Batch    32  of    431.    Elapsed:  0:00:01, Remaining:  0:00:00.\n",
      "  Batch    40  of    431.    Elapsed:  0:00:02, Remaining:  0:00:00.\n",
      "  Batch    48  of    431.    Elapsed:  0:00:02, Remaining:  0:00:00.\n",
      "  Batch    56  of    431.    Elapsed:  0:00:02, Remaining:  0:00:00.\n",
      "  Batch    64  of    431.    Elapsed:  0:00:03, Remaining:  0:00:00.\n",
      "  Batch    72  of    431.    Elapsed:  0:00:03, Remaining:  0:00:00.\n",
      "  Batch    80  of    431.    Elapsed:  0:00:03, Remaining:  0:00:00.\n",
      "  Batch    88  of    431.    Elapsed:  0:00:04, Remaining:  0:00:00.\n",
      "  Batch    96  of    431.    Elapsed:  0:00:04, Remaining:  0:00:00.\n",
      "  Batch   104  of    431.    Elapsed:  0:00:04, Remaining:  0:00:00.\n",
      "  Batch   112  of    431.    Elapsed:  0:00:05, Remaining:  0:00:00.\n",
      "  Batch   120  of    431.    Elapsed:  0:00:05, Remaining:  0:00:00.\n",
      "  Batch   128  of    431.    Elapsed:  0:00:05, Remaining:  0:00:00.\n",
      "  Batch   136  of    431.    Elapsed:  0:00:06, Remaining:  0:00:00.\n",
      "  Batch   144  of    431.    Elapsed:  0:00:06, Remaining:  0:00:00.\n",
      "  Batch   152  of    431.    Elapsed:  0:00:06, Remaining:  0:00:00.\n",
      "  Batch   160  of    431.    Elapsed:  0:00:07, Remaining:  0:00:00.\n",
      "  Batch   168  of    431.    Elapsed:  0:00:07, Remaining:  0:00:00.\n",
      "  Batch   176  of    431.    Elapsed:  0:00:07, Remaining:  0:00:00.\n",
      "  Batch   184  of    431.    Elapsed:  0:00:08, Remaining:  0:00:00.\n",
      "  Batch   192  of    431.    Elapsed:  0:00:08, Remaining:  0:00:00.\n",
      "  Batch   200  of    431.    Elapsed:  0:00:08, Remaining:  0:00:00.\n",
      "  Batch   208  of    431.    Elapsed:  0:00:09, Remaining:  0:00:00.\n",
      "  Batch   216  of    431.    Elapsed:  0:00:09, Remaining:  0:00:00.\n",
      "  Batch   224  of    431.    Elapsed:  0:00:09, Remaining:  0:00:00.\n",
      "  Batch   232  of    431.    Elapsed:  0:00:10, Remaining:  0:00:00.\n",
      "  Batch   240  of    431.    Elapsed:  0:00:10, Remaining:  0:00:00.\n",
      "  Batch   248  of    431.    Elapsed:  0:00:10, Remaining:  0:00:00.\n",
      "  Batch   256  of    431.    Elapsed:  0:00:11, Remaining:  0:00:00.\n",
      "  Batch   264  of    431.    Elapsed:  0:00:11, Remaining:  0:00:00.\n",
      "  Batch   272  of    431.    Elapsed:  0:00:11, Remaining:  0:00:00.\n",
      "  Batch   280  of    431.    Elapsed:  0:00:12, Remaining:  0:00:00.\n",
      "  Batch   288  of    431.    Elapsed:  0:00:12, Remaining:  0:00:00.\n",
      "  Batch   296  of    431.    Elapsed:  0:00:12, Remaining:  0:00:00.\n",
      "  Batch   304  of    431.    Elapsed:  0:00:13, Remaining:  0:00:00.\n",
      "  Batch   312  of    431.    Elapsed:  0:00:13, Remaining:  0:00:00.\n",
      "  Batch   320  of    431.    Elapsed:  0:00:13, Remaining:  0:00:00.\n",
      "  Batch   328  of    431.    Elapsed:  0:00:14, Remaining:  0:00:00.\n",
      "  Batch   336  of    431.    Elapsed:  0:00:14, Remaining:  0:00:00.\n",
      "  Batch   344  of    431.    Elapsed:  0:00:14, Remaining:  0:00:00.\n",
      "  Batch   352  of    431.    Elapsed:  0:00:15, Remaining:  0:00:00.\n",
      "  Batch   360  of    431.    Elapsed:  0:00:15, Remaining:  0:00:00.\n",
      "  Batch   368  of    431.    Elapsed:  0:00:15, Remaining:  0:00:00.\n",
      "  Batch   376  of    431.    Elapsed:  0:00:16, Remaining:  0:00:00.\n",
      "  Batch   384  of    431.    Elapsed:  0:00:16, Remaining:  0:00:00.\n",
      "  Batch   392  of    431.    Elapsed:  0:00:16, Remaining:  0:00:00.\n",
      "  Batch   400  of    431.    Elapsed:  0:00:17, Remaining:  0:00:00.\n",
      "  Batch   408  of    431.    Elapsed:  0:00:17, Remaining:  0:00:00.\n",
      "  Batch   416  of    431.    Elapsed:  0:00:17, Remaining:  0:00:00.\n",
      "  Batch   424  of    431.    Elapsed:  0:00:18, Remaining:  0:00:00.\n",
      "\n",
      "  Average training scores:\n",
      "    loss: 0.3937872078814252\n",
      "    accuracy: 0.494199535962877\n",
      "    per class f1: 0.7455299598571058\n",
      "    f1_micro: 0.7656373144772224\n",
      "    f1_macro: 0.9026682134570754\n",
      "    recall_micro: 0.7656373144772224\n",
      "    recall_macro: 0.9444895591647305\n",
      "    precision_micro: 0.7656373144772224\n",
      "    precision_macro: 0.9508700696055671\n",
      "  Training epoch took: 0:00:18\n",
      "\n",
      "Running Testing...\n",
      "  Average testing scores:\n",
      "    loss: 0.44617735886055493\n",
      "    accuracy: 0.391304347826087\n",
      "    per class f1: 0.6663561076604555\n",
      "    f1_micro: 0.6990769496204281\n",
      "    f1_macro: 0.8804347826086953\n",
      "    recall_micro: 0.6990769496204281\n",
      "    recall_macro: 0.9336956521739131\n",
      "    precision_micro: 0.6990769496204281\n",
      "    precision_macro: 0.9336956521739131\n",
      "  Testing took: 0:00:01\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "\n",
      "Training...\n",
      "  Batch     8  of    431.    Elapsed:  0:00:00, Remaining:  0:00:00.\n",
      "  Batch    16  of    431.    Elapsed:  0:00:01, Remaining:  0:00:00.\n",
      "  Batch    24  of    431.    Elapsed:  0:00:01, Remaining:  0:00:00.\n",
      "  Batch    32  of    431.    Elapsed:  0:00:01, Remaining:  0:00:00.\n",
      "  Batch    40  of    431.    Elapsed:  0:00:02, Remaining:  0:00:00.\n",
      "  Batch    48  of    431.    Elapsed:  0:00:02, Remaining:  0:00:00.\n",
      "  Batch    56  of    431.    Elapsed:  0:00:02, Remaining:  0:00:00.\n",
      "  Batch    64  of    431.    Elapsed:  0:00:03, Remaining:  0:00:00.\n",
      "  Batch    72  of    431.    Elapsed:  0:00:03, Remaining:  0:00:00.\n",
      "  Batch    80  of    431.    Elapsed:  0:00:03, Remaining:  0:00:00.\n",
      "  Batch    88  of    431.    Elapsed:  0:00:04, Remaining:  0:00:00.\n",
      "  Batch    96  of    431.    Elapsed:  0:00:04, Remaining:  0:00:00.\n",
      "  Batch   104  of    431.    Elapsed:  0:00:04, Remaining:  0:00:00.\n",
      "  Batch   112  of    431.    Elapsed:  0:00:05, Remaining:  0:00:00.\n",
      "  Batch   120  of    431.    Elapsed:  0:00:05, Remaining:  0:00:00.\n",
      "  Batch   128  of    431.    Elapsed:  0:00:05, Remaining:  0:00:00.\n",
      "  Batch   136  of    431.    Elapsed:  0:00:06, Remaining:  0:00:00.\n",
      "  Batch   144  of    431.    Elapsed:  0:00:06, Remaining:  0:00:00.\n",
      "  Batch   152  of    431.    Elapsed:  0:00:06, Remaining:  0:00:00.\n",
      "  Batch   160  of    431.    Elapsed:  0:00:07, Remaining:  0:00:00.\n",
      "  Batch   168  of    431.    Elapsed:  0:00:07, Remaining:  0:00:00.\n",
      "  Batch   176  of    431.    Elapsed:  0:00:07, Remaining:  0:00:00.\n",
      "  Batch   184  of    431.    Elapsed:  0:00:08, Remaining:  0:00:00.\n",
      "  Batch   192  of    431.    Elapsed:  0:00:08, Remaining:  0:00:00.\n",
      "  Batch   200  of    431.    Elapsed:  0:00:08, Remaining:  0:00:00.\n",
      "  Batch   208  of    431.    Elapsed:  0:00:09, Remaining:  0:00:00.\n",
      "  Batch   216  of    431.    Elapsed:  0:00:09, Remaining:  0:00:00.\n",
      "  Batch   224  of    431.    Elapsed:  0:00:09, Remaining:  0:00:00.\n",
      "  Batch   232  of    431.    Elapsed:  0:00:10, Remaining:  0:00:00.\n",
      "  Batch   240  of    431.    Elapsed:  0:00:10, Remaining:  0:00:00.\n",
      "  Batch   248  of    431.    Elapsed:  0:00:10, Remaining:  0:00:00.\n",
      "  Batch   256  of    431.    Elapsed:  0:00:11, Remaining:  0:00:00.\n",
      "  Batch   264  of    431.    Elapsed:  0:00:11, Remaining:  0:00:00.\n",
      "  Batch   272  of    431.    Elapsed:  0:00:11, Remaining:  0:00:00.\n",
      "  Batch   280  of    431.    Elapsed:  0:00:12, Remaining:  0:00:00.\n",
      "  Batch   288  of    431.    Elapsed:  0:00:12, Remaining:  0:00:00.\n",
      "  Batch   296  of    431.    Elapsed:  0:00:12, Remaining:  0:00:00.\n",
      "  Batch   304  of    431.    Elapsed:  0:00:13, Remaining:  0:00:00.\n",
      "  Batch   312  of    431.    Elapsed:  0:00:13, Remaining:  0:00:00.\n",
      "  Batch   320  of    431.    Elapsed:  0:00:13, Remaining:  0:00:00.\n",
      "  Batch   328  of    431.    Elapsed:  0:00:14, Remaining:  0:00:00.\n",
      "  Batch   336  of    431.    Elapsed:  0:00:14, Remaining:  0:00:00.\n",
      "  Batch   344  of    431.    Elapsed:  0:00:14, Remaining:  0:00:00.\n",
      "  Batch   352  of    431.    Elapsed:  0:00:15, Remaining:  0:00:00.\n",
      "  Batch   360  of    431.    Elapsed:  0:00:15, Remaining:  0:00:00.\n",
      "  Batch   368  of    431.    Elapsed:  0:00:15, Remaining:  0:00:00.\n",
      "  Batch   376  of    431.    Elapsed:  0:00:16, Remaining:  0:00:00.\n",
      "  Batch   384  of    431.    Elapsed:  0:00:16, Remaining:  0:00:00.\n",
      "  Batch   392  of    431.    Elapsed:  0:00:16, Remaining:  0:00:00.\n",
      "  Batch   400  of    431.    Elapsed:  0:00:17, Remaining:  0:00:00.\n",
      "  Batch   408  of    431.    Elapsed:  0:00:17, Remaining:  0:00:00.\n",
      "  Batch   416  of    431.    Elapsed:  0:00:17, Remaining:  0:00:00.\n",
      "  Batch   424  of    431.    Elapsed:  0:00:18, Remaining:  0:00:00.\n",
      "\n",
      "  Average training scores:\n",
      "    loss: 0.27504289293717893\n",
      "    accuracy: 0.722737819025522\n",
      "    per class f1: 0.8785898427429754\n",
      "    f1_micro: 0.8860162781276466\n",
      "    f1_macro: 0.9510827532869294\n",
      "    recall_micro: 0.8860162781276466\n",
      "    recall_macro: 0.9723317865429225\n",
      "    precision_micro: 0.8860162781276466\n",
      "    precision_macro: 0.9748839907192575\n",
      "  Training epoch took: 0:00:18\n",
      "\n",
      "Running Testing...\n",
      "  Average testing scores:\n",
      "    loss: 0.43614364059075067\n",
      "    accuracy: 0.391304347826087\n",
      "    per class f1: 0.6790027605244997\n",
      "    f1_micro: 0.7066338854382335\n",
      "    f1_macro: 0.8815217391304344\n",
      "    recall_micro: 0.7066338854382335\n",
      "    recall_macro: 0.9347826086956523\n",
      "    precision_micro: 0.7066338854382335\n",
      "    precision_macro: 0.9326086956521741\n",
      "  Testing took: 0:00:01\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "\n",
      "Training...\n",
      "  Batch     8  of    431.    Elapsed:  0:00:00, Remaining:  0:00:00.\n",
      "  Batch    16  of    431.    Elapsed:  0:00:01, Remaining:  0:00:00.\n",
      "  Batch    24  of    431.    Elapsed:  0:00:01, Remaining:  0:00:00.\n",
      "  Batch    32  of    431.    Elapsed:  0:00:01, Remaining:  0:00:00.\n",
      "  Batch    40  of    431.    Elapsed:  0:00:02, Remaining:  0:00:00.\n",
      "  Batch    48  of    431.    Elapsed:  0:00:02, Remaining:  0:00:00.\n",
      "  Batch    56  of    431.    Elapsed:  0:00:02, Remaining:  0:00:00.\n",
      "  Batch    64  of    431.    Elapsed:  0:00:03, Remaining:  0:00:00.\n",
      "  Batch    72  of    431.    Elapsed:  0:00:03, Remaining:  0:00:00.\n",
      "  Batch    80  of    431.    Elapsed:  0:00:03, Remaining:  0:00:00.\n",
      "  Batch    88  of    431.    Elapsed:  0:00:04, Remaining:  0:00:00.\n",
      "  Batch    96  of    431.    Elapsed:  0:00:04, Remaining:  0:00:00.\n",
      "  Batch   104  of    431.    Elapsed:  0:00:04, Remaining:  0:00:00.\n",
      "  Batch   112  of    431.    Elapsed:  0:00:05, Remaining:  0:00:00.\n",
      "  Batch   120  of    431.    Elapsed:  0:00:05, Remaining:  0:00:00.\n",
      "  Batch   128  of    431.    Elapsed:  0:00:05, Remaining:  0:00:00.\n",
      "  Batch   136  of    431.    Elapsed:  0:00:06, Remaining:  0:00:00.\n",
      "  Batch   144  of    431.    Elapsed:  0:00:06, Remaining:  0:00:00.\n",
      "  Batch   152  of    431.    Elapsed:  0:00:06, Remaining:  0:00:00.\n",
      "  Batch   160  of    431.    Elapsed:  0:00:07, Remaining:  0:00:00.\n",
      "  Batch   168  of    431.    Elapsed:  0:00:07, Remaining:  0:00:00.\n",
      "  Batch   176  of    431.    Elapsed:  0:00:07, Remaining:  0:00:00.\n",
      "  Batch   184  of    431.    Elapsed:  0:00:08, Remaining:  0:00:00.\n",
      "  Batch   192  of    431.    Elapsed:  0:00:08, Remaining:  0:00:00.\n",
      "  Batch   200  of    431.    Elapsed:  0:00:09, Remaining:  0:00:00.\n",
      "  Batch   208  of    431.    Elapsed:  0:00:09, Remaining:  0:00:00.\n",
      "  Batch   216  of    431.    Elapsed:  0:00:09, Remaining:  0:00:00.\n",
      "  Batch   224  of    431.    Elapsed:  0:00:10, Remaining:  0:00:00.\n",
      "  Batch   232  of    431.    Elapsed:  0:00:10, Remaining:  0:00:00.\n",
      "  Batch   240  of    431.    Elapsed:  0:00:10, Remaining:  0:00:00.\n",
      "  Batch   248  of    431.    Elapsed:  0:00:11, Remaining:  0:00:00.\n",
      "  Batch   256  of    431.    Elapsed:  0:00:11, Remaining:  0:00:00.\n",
      "  Batch   264  of    431.    Elapsed:  0:00:11, Remaining:  0:00:00.\n",
      "  Batch   272  of    431.    Elapsed:  0:00:12, Remaining:  0:00:00.\n",
      "  Batch   280  of    431.    Elapsed:  0:00:12, Remaining:  0:00:00.\n",
      "  Batch   288  of    431.    Elapsed:  0:00:12, Remaining:  0:00:00.\n",
      "  Batch   296  of    431.    Elapsed:  0:00:13, Remaining:  0:00:00.\n",
      "  Batch   304  of    431.    Elapsed:  0:00:13, Remaining:  0:00:00.\n",
      "  Batch   312  of    431.    Elapsed:  0:00:13, Remaining:  0:00:00.\n",
      "  Batch   320  of    431.    Elapsed:  0:00:14, Remaining:  0:00:00.\n",
      "  Batch   328  of    431.    Elapsed:  0:00:14, Remaining:  0:00:00.\n",
      "  Batch   336  of    431.    Elapsed:  0:00:14, Remaining:  0:00:00.\n",
      "  Batch   344  of    431.    Elapsed:  0:00:15, Remaining:  0:00:00.\n",
      "  Batch   352  of    431.    Elapsed:  0:00:15, Remaining:  0:00:00.\n",
      "  Batch   360  of    431.    Elapsed:  0:00:15, Remaining:  0:00:00.\n",
      "  Batch   368  of    431.    Elapsed:  0:00:16, Remaining:  0:00:00.\n",
      "  Batch   376  of    431.    Elapsed:  0:00:16, Remaining:  0:00:00.\n",
      "  Batch   384  of    431.    Elapsed:  0:00:16, Remaining:  0:00:00.\n",
      "  Batch   392  of    431.    Elapsed:  0:00:17, Remaining:  0:00:00.\n",
      "  Batch   400  of    431.    Elapsed:  0:00:17, Remaining:  0:00:00.\n",
      "  Batch   408  of    431.    Elapsed:  0:00:17, Remaining:  0:00:00.\n",
      "  Batch   416  of    431.    Elapsed:  0:00:18, Remaining:  0:00:00.\n",
      "  Batch   424  of    431.    Elapsed:  0:00:18, Remaining:  0:00:00.\n",
      "\n",
      "  Average training scores:\n",
      "    loss: 0.1966250602441155\n",
      "    accuracy: 0.8689095127610209\n",
      "    per class f1: 0.9467664714764484\n",
      "    f1_micro: 0.9508304791367437\n",
      "    f1_macro: 0.9777648878576951\n",
      "    recall_micro: 0.9508304791367437\n",
      "    recall_macro: 0.9875290023201849\n",
      "    precision_micro: 0.9508304791367437\n",
      "    precision_macro: 0.9883990719257539\n",
      "  Training epoch took: 0:00:18\n",
      "\n",
      "Running Testing...\n",
      "  Average testing scores:\n",
      "    loss: 0.44945492125723674\n",
      "    accuracy: 0.358695652173913\n",
      "    per class f1: 0.6794340924775709\n",
      "    f1_micro: 0.6983005521049\n",
      "    f1_macro: 0.8807971014492751\n",
      "    recall_micro: 0.6983005521049\n",
      "    recall_macro: 0.9347826086956523\n",
      "    precision_micro: 0.6983005521049\n",
      "    precision_macro: 0.931521739130435\n",
      "  Testing took: 0:00:01\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "\n",
      "Training...\n",
      "  Batch     8  of    431.    Elapsed:  0:00:00, Remaining:  0:00:00.\n",
      "  Batch    16  of    431.    Elapsed:  0:00:01, Remaining:  0:00:00.\n",
      "  Batch    24  of    431.    Elapsed:  0:00:01, Remaining:  0:00:00.\n",
      "  Batch    32  of    431.    Elapsed:  0:00:01, Remaining:  0:00:00.\n",
      "  Batch    40  of    431.    Elapsed:  0:00:02, Remaining:  0:00:00.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stats = train_bern_model(\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    EPOCHS,\n",
    "    device,\n",
    "    loss_function,\n",
    "    id2label,\n",
    "    batch_schema=batch_schema,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    print_status=True,\n",
    "    is_hf_model=IS_HF_MODEL,\n",
    "    checkpoint_path=CHECKPOINT_PATH,\n",
    "    train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    test_batch_size=TEST_BATCH_SIZE,\n",
    "    only_save_core=False,\n",
    "    one_label_only=ONE_LABEL_ONLY,\n",
    "    mixed_lm_task=False,\n",
    "    mixed_lm_loss_function=nn.CrossEntropyLoss(),\n",
    "    \n",
    "    generic_output_class=True,\n",
    "    \n",
    "    #forward_args=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"],\n",
    "    #forward_args=[\"input_ids\"],\n",
    "\n",
    "    add_layers_on_stagnation=False,\n",
    "    num_layers_to_add=1,\n",
    "    add_layers_threshold=0.01, #0.005,\n",
    "    plot_k_topics=False,\n",
    "\n",
    "    batch_hack_train=True,\n",
    "    mlm_decode_n=0,#.0075,\n",
    "    tokenizer=tokenizer,\n",
    "\n",
    "    masked_lm_task=False,\n",
    "    check_run=CHECK_RUN,\n",
    "    retain_graph=False,\n",
    "\n",
    "    calc_metrics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "## SST 2 test\n",
    "## [loss] / [acc/ham]\n",
    "\n",
    "# 35k\n",
    "# .61 / .79 epoch 4 ; .59 / .78 epoch 3 ; .52 / .776 epoch 2 15k pretraining, num_labels=2\n",
    "\n",
    "# .48 / .80 epoch 3\n",
    "\n",
    "\n",
    "# 10k\n",
    "# .51 / .758 epoch 2 empty\n",
    "# .57 / .778 epoch 3 empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# hf bert (empty): batch_size=6, time per epoch=6:30min, 5734MiB VRAM, 0.756 0.786 epoch 6\n",
    "# hf t5 (empty): batch_size=6, time per epoch=5:17min, 5306MiB VRAM, 0.758 0.773 epoch 5\n",
    "# hf t5 (empty) num_layers=12 num_heads=12: batch_size=3, time per epoch=11:45min, 7416MiB VRAM, 0.758 0.787 epoch 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
