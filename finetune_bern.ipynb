{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/pushshift/cc-phoebe/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "import os\n",
    "import datetime\n",
    "import math\n",
    "import datasets\n",
    "from datasets import DatasetDict, load_dataset, Dataset\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import AdamW\n",
    "from torch import nn\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    T5Tokenizer,\n",
    "    T5ForSequenceClassification,\n",
    "    T5Config,\n",
    "    BertTokenizer, \n",
    "    RobertaTokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from load_set import load_set\n",
    "from epoch_stats import EpochStats#, print_stat_tuples\n",
    "import model_training\n",
    "from model_training import (\n",
    "    BatchBuffer, \n",
    "    train_bern_model, \n",
    "    mask_tokens, \n",
    "    preprocess_with_given_labels, \n",
    "    num_parameters, \n",
    "    num_trainable_parameters, \n",
    "    preprocess_for_causallm, \n",
    "    preprocess_for_multiple_choice,\n",
    "    preprocess_for_seq2seq_swag\n",
    ")\n",
    "import bert_i1_1_modeling as bert_i1_1\n",
    "import coin_i2C_modeling as ci2C\n",
    "import coin_i2D_modeling as ci2D\n",
    "import coin_i3A_modeling as ci3A\n",
    "import coin_i3B_modeling as ci3B\n",
    "import coin_i3C_modeling as ci3C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_FILE = 1\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "TEST_BATCH_SIZE = 8\n",
    "CHECKPOINT_PATH = None # datetime.datetime.now().strftime(\"tmp_models/rann_sffn/run_part_load_%Y-%m-%d_%H:%M:%S\")\n",
    "USE_CUSTOM_DATALOADER = True\n",
    "SHUFFLE_CUSTOM_DATALOADER = True\n",
    "LEARNING_RATE = 1e-5\n",
    "EPS = 1e-8\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 30_522\n",
    "#VOCAB_SIZE = 32_000\n",
    "#VOCAB_SIZE = 52_000\n",
    "MAX_POSITION_EMBEDDINGS = 128#24**2#512\n",
    "IS_HF_MODEL = False\n",
    "GENERIC_OUTPUT_CLASS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALWAYS CHECK num_labels, RFFN doesn't throw an error on a wrong parameter\n",
    "rffn_base_model_path = \"tmp_models/COIN-i3C_mcca-translation-en-de_0029-500k_1x2_1dec-none_no-revert_chunkwise_group-exp_congen-head_B10_multi-query-2_switch-ii_mpe128/\"\n",
    "#rffn_base_model_path = \"tmp_models/COIN-i2B_oasst1_25k_1x3_000dec_none-decoder-revert-out_chunkwise_nt-case-3_2-decay-parts_allow-enc-tf/\"\n",
    "#rffn_base_model_path = \"tmp_models/RRB_oasst1_25k_2-2-encoder_0-1-decoder_decay_maskedLM.15_.2share_docx1_wtf/\"\n",
    "#rffn_tokenizer_path = \"pretrained_models/rffn_wikitext_516_tokenizer\"\n",
    "rffn_tokenizer_path = rffn_base_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default, sst2, swag, uni-main-hyp\n",
    "TEST_METHOD = \"sst2\"\n",
    "ILOC_LIMIT = None\n",
    "DEFAULT_TEACHER_FORCING = False\n",
    "DOC_PAD_TOKENS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST_METHOD == \"default\":\n",
    "    NUM_LABELS = 7\n",
    "elif TEST_METHOD == \"sst2\":\n",
    "    NUM_LABELS = 2\n",
    "elif TEST_METHOD == \"swag\":\n",
    "    NUM_LABELS = 4\n",
    "elif TEST_METHOD == \"uni-main-hyp\":\n",
    "    NUM_LABELS = 10\n",
    "\n",
    "TEST_SST2 = TEST_METHOD == \"sst2\"\n",
    "ONE_LABEL_ONLY = TEST_SST2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECK_RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    model = ci3C.COINForSequenceClassification(\n",
    "        config=ci3C.COINConfig(\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "            num_labels=NUM_LABELS,\n",
    "            forward_method=\"chunkwise\",\n",
    "            apply_decay=False,\n",
    "            num_decay_parts=2,\n",
    "            hidden_retention_act=\"relu\",\n",
    "            hidden_pos_offset=True,\n",
    "            rope_dim=16,\n",
    "            num_query_heads=2,\n",
    "\n",
    "            decoder_output=\"none\",\n",
    "            revert_decoder=False,\n",
    "            decoder_schema=[1, 1],\n",
    "            cross_encoder_schema=[0, 0],\n",
    "            experts_schema=None,#[2, 2],\n",
    "            block_io_schema=None,#[[1024, 1024*4, 1024], [1024, 1024*2, 1024]],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num layers: 2\n",
      "gamma schema: [[0.96875, 0.9875984191894531], [0.995078444480896, 0.998046875]]\n",
      "layer 0 num experts: 1\n",
      "layer 1 num experts: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of COINForSequenceClassification were not initialized from the model checkpoint at tmp_models/COIN-i3C_mcca-translation-en-de_0029-500k_1x2_1dec-none_no-revert_chunkwise_group-exp_congen-head_B10_multi-query-2_switch-ii_mpe128//model/epoch_9/model and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    N_ITER = 9\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    #tokenizer = RobertaTokenizer.from_pretrained(f\"{rffn_base_model_path}/bpe_tokenizer/\")\n",
    "    model = ci3C.COINForSequenceClassification.from_pretrained(\n",
    "        f\"{rffn_base_model_path}/model/epoch_{N_ITER}/model\",\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "        num_labels=NUM_LABELS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    model = ci3B.COINForSequenceClassification(\n",
    "        config=ci3B.COINConfig(\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "            num_labels=NUM_LABELS,\n",
    "            forward_method=\"parallel\",\n",
    "            apply_decay=False,\n",
    "            num_decay_parts=1,\n",
    "            hidden_retention_act=\"relu\",\n",
    "\n",
    "            decoder_output=\"strict\",\n",
    "            decoder_schema=[0, 1],\n",
    "            cross_encoder_schema=[0, 0],\n",
    "            experts_schema=None,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    model = ci3A.COINForSequenceClassification(\n",
    "        config=ci3A.COINConfig(\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "            num_labels=NUM_LABELS,\n",
    "            forward_method=\"parallel\",\n",
    "            apply_decay=False,\n",
    "            num_decay_parts=1,\n",
    "            hidden_retention_act=\"relu\",\n",
    "            apply_hidden_pos_offset=False,\n",
    "            #fuzed_decay_attention_mask=False,\n",
    "\n",
    "            decoder_output=\"none\",\n",
    "            revert_decoder=False,\n",
    "            decoder_schema=[1, 1],\n",
    "            cross_encoder_schema=[0] * 2,\n",
    "            experts_schema=None,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    N_ITER = 0\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    #tokenizer = RobertaTokenizer.from_pretrained(f\"{rffn_base_model_path}/bpe_tokenizer/\")\n",
    "    model = ci3A.COINForSequenceClassification.from_pretrained(\n",
    "        f\"{rffn_base_model_path}/model/epoch_{N_ITER}/model\",\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "        num_labels=NUM_LABELS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    #tokenizer = RobertaTokenizer.from_pretrained(f\"{rffn_base_model_path}/bpe_tokenizer/\")\n",
    "    NUM_REGIONS = 1\n",
    "    model = ci2D.COINForSequenceClassification(\n",
    "        config=ci2D.COINConfig(\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "            num_labels=NUM_LABELS,\n",
    "            hidden_retention_act=\"relu\",\n",
    "            #hidden_out_act=None,\n",
    "            forward_method=\"parallel\",\n",
    "            apply_decay=False,\n",
    "            reverse_decay=False,\n",
    "            num_decay_parts=1,\n",
    "            decoder_output=\"strict\",\n",
    "            #rope_dim=16,\n",
    "            \n",
    "            num_regions=NUM_REGIONS,\n",
    "            decoder_schema=      [0, 1],\n",
    "            cross_encoder_schema=[0, 0],\n",
    "            \n",
    "            share_S=False,\n",
    "            \n",
    "            #layer_norm_eps=1e-12,\n",
    "            #retention_group_norm_eps=1e-8,\n",
    "            #rms_norm_eps=1e-12,\n",
    "\n",
    "            disable_teacher_forcing=False,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    N_ITER = 0\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    #tokenizer = RobertaTokenizer.from_pretrained(f\"{rffn_base_model_path}/bpe_tokenizer/\")\n",
    "    model = ci2D.COINForSequenceClassification.from_pretrained(\n",
    "        f\"{rffn_base_model_path}/model/epoch_{N_ITER}/model\",\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "        num_labels=NUM_LABELS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    #tokenizer = RobertaTokenizer.from_pretrained(f\"{rffn_base_model_path}/bpe_tokenizer/\")\n",
    "    NUM_REGIONS = 1\n",
    "    model = ci2C.COINForSequenceClassification(\n",
    "        config=ci2C.COINConfig(\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "            num_labels=NUM_LABELS,\n",
    "            hidden_retention_act=\"relu\",\n",
    "            #hidden_out_act=None,\n",
    "            forward_method=\"parallel\",\n",
    "            apply_decay=False,\n",
    "            #fixed_decay_value=None,\n",
    "            num_decay_parts=1,\n",
    "            #reverse_decay=False,\n",
    "            chunkwise_num_chunks=4,\n",
    "            apply_chunking_globally=False,\n",
    "            #apply_hidden_pos_offset=False,\n",
    "            decoder_output=\"none\",\n",
    "            \n",
    "            num_regions=NUM_REGIONS,\n",
    "            decoder_schema=      [0],\n",
    "            cross_encoder_schema=[0],\n",
    "            multi_head_qkv=False,\n",
    "            num_heads=16,\n",
    "            share_S=False,\n",
    "            #num_repetitions=1,\n",
    "            add_residual_query_skip=False,\n",
    "\n",
    "            #layer_norm_eps=1e-12,\n",
    "            #retention_group_norm_eps=1e-8,\n",
    "            #rms_norm_eps=1e-12,\n",
    "\n",
    "            print_checks=CHECK_RUN,\n",
    "            reset_S_n_state=False,\n",
    "            disable_teacher_forcing=False,\n",
    "\n",
    "            apply_selective_attention_params=False,\n",
    "            #selective_param_Ns=(2, 2),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    N_ITER = 0\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{rffn_base_model_path}/wordpiece_tokenizer/\")\n",
    "    #tokenizer = RobertaTokenizer.from_pretrained(f\"{rffn_base_model_path}/bpe_tokenizer/\")\n",
    "    model = ci2C.COINForSequenceClassification.from_pretrained(\n",
    "        f\"{rffn_base_model_path}/model/epoch_{N_ITER}/model\",\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "        num_labels=NUM_LABELS,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")\n",
    "    class MambaOutput:\n",
    "        def __init__(self, out):\n",
    "            self.logits = out\n",
    "            self.encoder_hidden_state = None\n",
    "            self.S = None\n",
    "            self.C = None\n",
    "            self.loss = None\n",
    "            self.aux_loss = None\n",
    "\n",
    "    class MambaForSequenceClassification(nn.Module):\n",
    "        def __init__(self, path, **kwargs):\n",
    "            super().__init__()\n",
    "            self.mamba = transformers.MambaModel.from_pretrained(path, num_hidden_layers=12, **kwargs)\n",
    "            self.config = self.mamba.config\n",
    "            self.dense = nn.Linear(768, 768)\n",
    "            self.act = nn.Tanh()\n",
    "            self.cls = nn.Linear(768, NUM_LABELS)\n",
    "\n",
    "        def forward(self, **kwargs):\n",
    "            logits = self.mamba(**kwargs).last_hidden_state\n",
    "            out = self.act(self.dense(logits[:, 0, :]))\n",
    "            out = self.cls(out)\n",
    "            return MambaOutput(out)\n",
    "\n",
    "        \n",
    "    #model = transformers.MambaModel.from_pretrained(\"state-spaces/mamba-130m-hf\", num_labels=NUM_LABELS)\n",
    "    model = MambaForSequenceClassification(\"state-spaces/mamba-130m-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115,813,410\n",
      "115,813,378\n"
     ]
    }
   ],
   "source": [
    "print(\"{:,}\\n{:,}\".format(num_parameters(model), num_trainable_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ds_path = \"../datasets/big_AAABDON_Nmax_st200_s0_a10_tvsplit.1_no_norm/\"\n",
    "\n",
    "train_ds = [\n",
    "    f\"{base_ds_path}/train/train_00[0-{TO_FILE}].csv\"\n",
    "\n",
    "    #f\"datasets/big_AAABDON_Nmax_st200_s0_a10_tvsplit.1_no_norm/train/train_00[0-9].csv\",\n",
    "    #f\"datasets/big_AAABDON_Nmax_st200_s0_a10_tvsplit.1_no_norm/train/train_01[0-9].csv\"\n",
    "]\n",
    "test_ds = [\n",
    "    f\"{base_ds_path}/validation/validation_00[0-{TO_FILE}].csv\"\n",
    "\n",
    "    #f\"datasets/big_AAABDON_Nmax_st200_s0_a10_tvsplit.1_no_norm/validation/validation_00[0-9].csv\",\n",
    "    #f\"datasets/big_AAABDON_Nmax_st200_s0_a10_tvsplit.1_no_norm/validation/validation_01[0-9].csv\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if TEST_METHOD == \"sst2\":\n",
    "    dataset = DatasetDict({\n",
    "        \"train\": load_dataset(\"glue\", name=\"sst2\", split=\"train[:10000]\").rename_column(\"sentence\", \"text\"),\n",
    "        \"test\": load_dataset(\"glue\", name=\"sst2\", split=\"validation\").rename_column(\"sentence\", \"text\")\n",
    "    })\n",
    "elif TEST_METHOD == \"default\":\n",
    "    dataset = DatasetDict({\n",
    "        \"train\": load_set(train_ds, unused_fields=[\"author\", \"subreddit\", \"style\"], iloc_limit=ILOC_LIMIT),\n",
    "        \"test\":  load_set(test_ds, unused_fields=[\"author\", \"subreddit\", \"style\"], iloc_limit=ILOC_LIMIT)\n",
    "\n",
    "        #\"train\": load_dataset(\"glue\", name=\"mnli\", split=\"train[0:10000]\"),\n",
    "        #\"test\": load_dataset(\"glue\", name=\"mnli\", split=\"validation_matched[0:1500]\")\n",
    "\n",
    "        #\"train\": load_dataset(\"squad_v2\", split=\"train[0:10000]\"),\n",
    "        #\"test\": load_dataset(\"squad_v2\", split=\"test[0:1500]\")\n",
    "    })\n",
    "elif TEST_METHOD == \"swag\":\n",
    "    dataset = DatasetDict({\n",
    "        \"train\": load_dataset(\"Rowan/hellaswag\", split=\"train\"),\n",
    "        \"test\": load_dataset(\"Rowan/hellaswag\", split=\"validation\")\n",
    "    })\n",
    "elif TEST_METHOD == \"uni-main-hyp\":\n",
    "    DS_PATH = \"../uni-hyp-class/wordpiece_abstracts_train_side_label_1.csv\"\n",
    "    dataset = DatasetDict({\n",
    "        \"train\": load_set([DS_PATH], unused_fields=[\"head\", \"body\", \"strlabels\"]),\n",
    "        \"test\": load_set([DS_PATH], unused_fields=[\"head\", \"body\", \"strlabels\"]),\n",
    "    })\n",
    "else:\n",
    "    raise ValueError(TEST_METHOD)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1}\n",
      "{0: 0, 1: 1}\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "if ONE_LABEL_ONLY:\n",
    "    #labels = np.unique(train_df[\"label\"]).tolist()\n",
    "    labels = np.unique(dataset[\"train\"][\"label\"]).tolist()\n",
    "else:\n",
    "    labels = [label for label in dataset['train'].features.keys() if label not in [\"text\"]]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "print(label2id)\n",
    "print(id2label)\n",
    "print(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels', 'decoder_input_ids'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels', 'decoder_input_ids'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "if TEST_METHOD in (\"default\", \"sst2\", \"uni-main-hyp\"):\n",
    "    encoded_dataset = preprocess_with_given_labels(dataset, tokenizer, labels, label2id, MAX_POSITION_EMBEDDINGS, ONE_LABEL_ONLY, remove_columns=dataset[\"train\"].column_names, \n",
    "                                                   default_teacher_forcing=DEFAULT_TEACHER_FORCING, doc_pad_tokens=DOC_PAD_TOKENS)\n",
    "elif TEST_METHOD == \"swag\":\n",
    "    #encoded_dataset = preprocess_for_multiple_choice(dataset, tokenizer, MAX_POSITION_EMBEDDINGS, remove_columns=dataset[\"train\"].column_names, num_proc=4)\n",
    "    encoded_dataset = preprocess_for_seq2seq_swag(dataset, tokenizer, MAX_POSITION_EMBEDDINGS, remove_columns=dataset[\"train\"].column_names, num_proc=4)\n",
    "encoded_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids',\n",
       " 'token_type_ids',\n",
       " 'attention_mask',\n",
       " 'labels',\n",
       " 'decoder_input_ids']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "batch_schema = list(encoded_dataset[\"train\"].features.keys())\n",
    "batch_schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if USE_CUSTOM_DATALOADER:\n",
    "    #train_dataloader = create_dataloader(encoded_dataset[\"train\"])\n",
    "    #test_dataloader = create_dataloader(encoded_dataset[\"test\"])\n",
    "    train_dataloader = BatchBuffer(encoded_dataset[\"train\"], TRAIN_BATCH_SIZE)\n",
    "    if SHUFFLE_CUSTOM_DATALOADER:\n",
    "        train_dataloader.shuffle()\n",
    "    test_dataloader = BatchBuffer(encoded_dataset[\"test\"], TEST_BATCH_SIZE)\n",
    "else:\n",
    "    USE_TOKEN_TYPE_IDS = \"token_type_ids\" in encoded_dataset[\"train\"].features\n",
    "    USE_DEC_II = \"decoder_input_ids\" in encoded_dataset[\"train\"].features\n",
    "    # Load input data into tensors\n",
    "    train_input_ids = torch.tensor(encoded_dataset[\"train\"][\"input_ids\"])\n",
    "    if USE_TOKEN_TYPE_IDS:\n",
    "        train_token_type_ids = torch.tensor(encoded_dataset[\"train\"][\"token_type_ids\"])\n",
    "    train_masks = torch.tensor(encoded_dataset[\"train\"][\"attention_mask\"])\n",
    "    train_labels = torch.tensor(encoded_dataset[\"train\"][\"labels\"])\n",
    "    if USE_DEC_II:\n",
    "        train_dec_ii = torch.tensor(encoded_dataset[\"train\"][\"decoder_input_ids\"])\n",
    "\n",
    "    test_input_ids = torch.tensor(encoded_dataset[\"test\"][\"input_ids\"])\n",
    "    if USE_TOKEN_TYPE_IDS:\n",
    "        test_token_type_ids = torch.tensor(encoded_dataset[\"test\"][\"token_type_ids\"])\n",
    "    test_masks = torch.tensor(encoded_dataset[\"test\"][\"attention_mask\"])\n",
    "    test_labels = torch.tensor(encoded_dataset[\"test\"][\"labels\"])\n",
    "    if USE_DEC_II:\n",
    "        test_dec_ii = torch.tensor(encoded_dataset[\"test\"][\"decoder_input_ids\"])\n",
    "\n",
    "    # Create the DataLoader and Sampler for both sets.\n",
    "    if USE_TOKEN_TYPE_IDS:\n",
    "        train_data = TensorDataset(train_input_ids, train_token_type_ids, train_masks, train_labels)\n",
    "    else:\n",
    "        train_data = TensorDataset(train_input_ids, train_masks, train_labels)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, \n",
    "        sampler=train_sampler, \n",
    "        batch_size=BATCH_SIZE)\n",
    "\n",
    "    if USE_TOKEN_TYPE_IDS:\n",
    "        test_data = TensorDataset(test_input_ids, test_token_type_ids, test_masks, test_labels)\n",
    "    else:\n",
    "        test_data = TensorDataset(test_input_ids, test_masks, test_labels)\n",
    "    test_sampler = SequentialSampler(test_data)\n",
    "    test_dataloader = DataLoader(test_data, \n",
    "        sampler=test_sampler, \n",
    "        batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=EPS)\n",
    "\n",
    "total_steps = len(train_dataloader) / TRAIN_BATCH_SIZE * EPOCHS\n",
    "warmup_steps = math.ceil(total_steps * 0.05)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=warmup_steps,\n",
    "                                            num_training_steps=total_steps)\n",
    "\n",
    "if len(labels) <= 2:\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "else:\n",
    "    loss_function = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrossEntropyLoss()\n",
      "1562.5\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "print(loss_function)\n",
    "print(total_steps)\n",
    "print(warmup_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if CHECKPOINT_PATH is not None:\n",
    "    try:\n",
    "        os.mkdir(CHECKPOINT_PATH)\n",
    "    except OSError as err:\n",
    "        print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#len(encoded_dataset[\"train\"][\"input_ids\"]), len(encoded_dataset[\"train\"][\"input_ids\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids',\n",
       " 'token_type_ids',\n",
       " 'attention_mask',\n",
       " 'labels',\n",
       " 'decoder_input_ids']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "batch_schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COINForSequenceClassification(\n",
       "  (coin): COINModel(\n",
       "    (encoder_embeddings): COINEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder_embeddings): COINEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (residual_embeddings): COINEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (stack): COINStack(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x COINLayer(\n",
       "          (blocks): ModuleList(\n",
       "            (0): COINBlock(\n",
       "              (cross_qkv): MultiQueryQKV(\n",
       "                (rope): RotaryEmbedding()\n",
       "                (xpos): XPOS()\n",
       "                (act): ReLU()\n",
       "                (out_act): ReLU()\n",
       "                (group_norm): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (proj_G): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (cross_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (qkv): MultiQueryQKV(\n",
       "                (rope): RotaryEmbedding()\n",
       "                (xpos): XPOS()\n",
       "                (act): ReLU()\n",
       "                (out_act): ReLU()\n",
       "                (group_norm): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (proj_G): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): COINPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (act): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "COINConfig {\n",
       "  \"_name_or_path\": \"tmp_models/COIN-i3C_mcca-translation-en-de_0029-500k_1x2_1dec-none_no-revert_chunkwise_group-exp_congen-head_B10_multi-query-2_switch-ii_mpe128//model/epoch_9/model\",\n",
       "  \"allow_encoder_teacher_forcing\": false,\n",
       "  \"apply_decay\": false,\n",
       "  \"apply_decoder_heads\": true,\n",
       "  \"apply_ffn\": true,\n",
       "  \"apply_hidden_pos_offset\": false,\n",
       "  \"apply_softmax_gate\": true,\n",
       "  \"architectures\": [\n",
       "    \"COINForConditionalGeneration\"\n",
       "  ],\n",
       "  \"block_io_schema\": null,\n",
       "  \"cross_encoder_schema\": [\n",
       "    0,\n",
       "    0\n",
       "  ],\n",
       "  \"decoder_output\": \"none\",\n",
       "  \"decoder_schema\": [\n",
       "    1,\n",
       "    1\n",
       "  ],\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"disable_teacher_forcing\": false,\n",
       "  \"experts_schema\": null,\n",
       "  \"ffn_intermediate_factor\": 4,\n",
       "  \"ffn_intermediate_size\": 4096,\n",
       "  \"fixed_decay_value\": null,\n",
       "  \"fixed_ffn_intermediate_size\": false,\n",
       "  \"fixed_intermediate_size\": false,\n",
       "  \"forward_method\": \"chunkwise\",\n",
       "  \"global_recurrence_check\": false,\n",
       "  \"group_norm_channels\": 1024,\n",
       "  \"group_norm_num\": 32,\n",
       "  \"hidden_act\": \"tanh\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_out_act\": \"relu\",\n",
       "  \"hidden_pos_offset\": true,\n",
       "  \"hidden_retention_act\": \"relu\",\n",
       "  \"hidden_size\": 1024,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_factor\": 1,\n",
       "  \"intermediate_size\": 1024,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"local_recurrence_check\": false,\n",
       "  \"max_position_embeddings\": 128,\n",
       "  \"model_type\": \"Consecutive Chain-Of-Input Network\",\n",
       "  \"num_decay_parts\": 1,\n",
       "  \"num_global_chunks\": 4,\n",
       "  \"num_heads\": 32,\n",
       "  \"num_hidden_layers\": 2,\n",
       "  \"num_local_chunks\": 4,\n",
       "  \"num_query_heads\": 2,\n",
       "  \"num_regions\": 2,\n",
       "  \"num_repetitions\": 1,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"reset_S_n_state\": false,\n",
       "  \"retention_group_norm_eps\": 1e-05,\n",
       "  \"reverse_decay\": false,\n",
       "  \"revert_decoder\": false,\n",
       "  \"rms_norm_eps\": 1e-08,\n",
       "  \"rope_dim\": 16,\n",
       "  \"share_S\": false,\n",
       "  \"switch_ii_decoder_ii\": false,\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.40.1\",\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(threshold=100000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    31  of  1,250.    Elapsed:  0:00:02, Remaining:  0:01:19.\n",
      "  Batch    62  of  1,250.    Elapsed:  0:00:03, Remaining:  0:00:38.\n",
      "  Batch    93  of  1,250.    Elapsed:  0:00:04, Remaining:  0:00:37.\n",
      "  Batch   124  of  1,250.    Elapsed:  0:00:06, Remaining:  0:00:36.\n",
      "  Batch   155  of  1,250.    Elapsed:  0:00:07, Remaining:  0:00:35.\n",
      "  Batch   186  of  1,250.    Elapsed:  0:00:09, Remaining:  0:00:34.\n",
      "  Batch   217  of  1,250.    Elapsed:  0:00:10, Remaining:  0:00:33.\n",
      "  Batch   248  of  1,250.    Elapsed:  0:00:11, Remaining:  0:00:32.\n",
      "  Batch   279  of  1,250.    Elapsed:  0:00:13, Remaining:  0:00:31.\n",
      "  Batch   310  of  1,250.    Elapsed:  0:00:14, Remaining:  0:00:30.\n",
      "  Batch   341  of  1,250.    Elapsed:  0:00:15, Remaining:  0:00:29.\n",
      "  Batch   372  of  1,250.    Elapsed:  0:00:17, Remaining:  0:00:28.\n",
      "  Batch   403  of  1,250.    Elapsed:  0:00:18, Remaining:  0:00:27.\n",
      "  Batch   434  of  1,250.    Elapsed:  0:00:19, Remaining:  0:00:26.\n",
      "  Batch   465  of  1,250.    Elapsed:  0:00:21, Remaining:  0:00:25.\n",
      "  Batch   496  of  1,250.    Elapsed:  0:00:22, Remaining:  0:00:24.\n",
      "  Batch   527  of  1,250.    Elapsed:  0:00:23, Remaining:  0:00:23.\n",
      "  Batch   558  of  1,250.    Elapsed:  0:00:24, Remaining:  0:00:22.\n",
      "  Batch   589  of  1,250.    Elapsed:  0:00:26, Remaining:  0:00:21.\n",
      "  Batch   620  of  1,250.    Elapsed:  0:00:27, Remaining:  0:00:20.\n",
      "  Batch   651  of  1,250.    Elapsed:  0:00:28, Remaining:  0:00:19.\n",
      "  Batch   682  of  1,250.    Elapsed:  0:00:30, Remaining:  0:00:18.\n",
      "  Batch   713  of  1,250.    Elapsed:  0:00:31, Remaining:  0:00:17.\n",
      "  Batch   744  of  1,250.    Elapsed:  0:00:32, Remaining:  0:00:16.\n",
      "  Batch   775  of  1,250.    Elapsed:  0:00:34, Remaining:  0:00:15.\n",
      "  Batch   806  of  1,250.    Elapsed:  0:00:35, Remaining:  0:00:14.\n",
      "  Batch   837  of  1,250.    Elapsed:  0:00:36, Remaining:  0:00:13.\n",
      "  Batch   868  of  1,250.    Elapsed:  0:00:38, Remaining:  0:00:12.\n",
      "  Batch   899  of  1,250.    Elapsed:  0:00:39, Remaining:  0:00:11.\n",
      "  Batch   930  of  1,250.    Elapsed:  0:00:40, Remaining:  0:00:10.\n",
      "  Batch   961  of  1,250.    Elapsed:  0:00:41, Remaining:  0:00:09.\n",
      "  Batch   992  of  1,250.    Elapsed:  0:00:43, Remaining:  0:00:08.\n",
      "  Batch 1,023  of  1,250.    Elapsed:  0:00:44, Remaining:  0:00:07.\n",
      "  Batch 1,054  of  1,250.    Elapsed:  0:00:45, Remaining:  0:00:06.\n",
      "  Batch 1,085  of  1,250.    Elapsed:  0:00:47, Remaining:  0:00:05.\n",
      "  Batch 1,116  of  1,250.    Elapsed:  0:00:48, Remaining:  0:00:04.\n",
      "  Batch 1,147  of  1,250.    Elapsed:  0:00:49, Remaining:  0:00:03.\n",
      "  Batch 1,178  of  1,250.    Elapsed:  0:00:50, Remaining:  0:00:02.\n",
      "  Batch 1,209  of  1,250.    Elapsed:  0:00:52, Remaining:  0:00:01.\n",
      "  Batch 1,240  of  1,250.    Elapsed:  0:00:53, Remaining:  0:00:00.\n",
      "\n",
      "  Average training scores:\n",
      "    loss: 0.5395163339078426\n",
      "    accuracy: 0.7274\n",
      "    hamming: 0.7274\n",
      "    f1_micro: 0.7274\n",
      "    f1_macro: 0.684209936729938\n",
      "    recall_micro: 0.7274\n",
      "    recall_macro: 0.7209180952380957\n",
      "    precision_micro: 0.7274\n",
      "    precision_macro: 0.7468076190476186\n",
      "  Training epoch took: 0:00:53\n",
      "\n",
      "Running Testing...\n",
      "  Average testing scores:\n",
      "    loss: 0.5432748805577738\n",
      "    accuracy: 0.7649082568807339\n",
      "    hamming: 0.7649082568807339\n",
      "    f1_micro: 0.7649082568807339\n",
      "    f1_macro: 0.7358485551146106\n",
      "    recall_micro: 0.7649082568807339\n",
      "    recall_macro: 0.7594473569244212\n",
      "    precision_micro: 0.7649082568807339\n",
      "    precision_macro: 0.770352774137178\n",
      "  Testing took: 0:00:02\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "\n",
      "Training...\n",
      "  Batch    31  of  1,250.    Elapsed:  0:00:01, Remaining:  0:00:39.\n",
      "  Batch    62  of  1,250.    Elapsed:  0:00:03, Remaining:  0:00:38.\n",
      "  Batch    93  of  1,250.    Elapsed:  0:00:04, Remaining:  0:00:37.\n",
      "  Batch   124  of  1,250.    Elapsed:  0:00:05, Remaining:  0:00:36.\n",
      "  Batch   155  of  1,250.    Elapsed:  0:00:07, Remaining:  0:00:35.\n",
      "  Batch   186  of  1,250.    Elapsed:  0:00:08, Remaining:  0:00:34.\n",
      "  Batch   217  of  1,250.    Elapsed:  0:00:09, Remaining:  0:00:33.\n",
      "  Batch   248  of  1,250.    Elapsed:  0:00:10, Remaining:  0:00:32.\n",
      "  Batch   279  of  1,250.    Elapsed:  0:00:12, Remaining:  0:00:31.\n",
      "  Batch   310  of  1,250.    Elapsed:  0:00:13, Remaining:  0:00:30.\n",
      "  Batch   341  of  1,250.    Elapsed:  0:00:14, Remaining:  0:00:29.\n",
      "  Batch   372  of  1,250.    Elapsed:  0:00:15, Remaining:  0:00:28.\n",
      "  Batch   403  of  1,250.    Elapsed:  0:00:17, Remaining:  0:00:27.\n",
      "  Batch   434  of  1,250.    Elapsed:  0:00:18, Remaining:  0:00:26.\n",
      "  Batch   465  of  1,250.    Elapsed:  0:00:19, Remaining:  0:00:25.\n",
      "  Batch   496  of  1,250.    Elapsed:  0:00:21, Remaining:  0:00:24.\n",
      "  Batch   527  of  1,250.    Elapsed:  0:00:22, Remaining:  0:00:23.\n",
      "  Batch   558  of  1,250.    Elapsed:  0:00:23, Remaining:  0:00:22.\n",
      "  Batch   589  of  1,250.    Elapsed:  0:00:25, Remaining:  0:00:21.\n",
      "  Batch   620  of  1,250.    Elapsed:  0:00:26, Remaining:  0:00:20.\n",
      "  Batch   651  of  1,250.    Elapsed:  0:00:27, Remaining:  0:00:19.\n",
      "  Batch   682  of  1,250.    Elapsed:  0:00:29, Remaining:  0:00:18.\n",
      "  Batch   713  of  1,250.    Elapsed:  0:00:30, Remaining:  0:00:17.\n",
      "  Batch   744  of  1,250.    Elapsed:  0:00:31, Remaining:  0:00:16.\n",
      "  Batch   775  of  1,250.    Elapsed:  0:00:33, Remaining:  0:00:15.\n",
      "  Batch   806  of  1,250.    Elapsed:  0:00:34, Remaining:  0:00:14.\n",
      "  Batch   837  of  1,250.    Elapsed:  0:00:35, Remaining:  0:00:13.\n",
      "  Batch   868  of  1,250.    Elapsed:  0:00:36, Remaining:  0:00:12.\n",
      "  Batch   899  of  1,250.    Elapsed:  0:00:38, Remaining:  0:00:11.\n",
      "  Batch   930  of  1,250.    Elapsed:  0:00:39, Remaining:  0:00:10.\n",
      "  Batch   961  of  1,250.    Elapsed:  0:00:40, Remaining:  0:00:09.\n",
      "  Batch   992  of  1,250.    Elapsed:  0:00:42, Remaining:  0:00:08.\n",
      "  Batch 1,023  of  1,250.    Elapsed:  0:00:43, Remaining:  0:00:07.\n",
      "  Batch 1,054  of  1,250.    Elapsed:  0:00:44, Remaining:  0:00:06.\n",
      "  Batch 1,085  of  1,250.    Elapsed:  0:00:45, Remaining:  0:00:05.\n",
      "  Batch 1,116  of  1,250.    Elapsed:  0:00:47, Remaining:  0:00:04.\n",
      "  Batch 1,147  of  1,250.    Elapsed:  0:00:48, Remaining:  0:00:03.\n",
      "  Batch 1,178  of  1,250.    Elapsed:  0:00:49, Remaining:  0:00:02.\n",
      "  Batch 1,209  of  1,250.    Elapsed:  0:00:50, Remaining:  0:00:01.\n",
      "  Batch 1,240  of  1,250.    Elapsed:  0:00:52, Remaining:  0:00:00.\n",
      "\n",
      "  Average training scores:\n",
      "    loss: 0.3264102223187685\n",
      "    accuracy: 0.8625\n",
      "    hamming: 0.8625\n",
      "    f1_micro: 0.8625\n",
      "    f1_macro: 0.8433918037518068\n",
      "    recall_micro: 0.8625\n",
      "    recall_macro: 0.8613157142857142\n",
      "    precision_micro: 0.8625\n",
      "    precision_macro: 0.8637647619047615\n",
      "  Training epoch took: 0:00:52\n",
      "\n",
      "Running Testing...\n",
      "  Average testing scores:\n",
      "    loss: 0.5745513704819006\n",
      "    accuracy: 0.7706422018348624\n",
      "    hamming: 0.7706422018348624\n",
      "    f1_micro: 0.7706422018348624\n",
      "    f1_macro: 0.7420593677474414\n",
      "    recall_micro: 0.7706422018348624\n",
      "    recall_macro: 0.7639908256880735\n",
      "    precision_micro: 0.7706422018348624\n",
      "    precision_macro: 0.7751802096985585\n",
      "  Testing took: 0:00:02\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "\n",
      "Training...\n",
      "  Batch    31  of  1,250.    Elapsed:  0:00:02, Remaining:  0:01:19.\n",
      "  Batch    62  of  1,250.    Elapsed:  0:00:03, Remaining:  0:00:38.\n",
      "  Batch    93  of  1,250.    Elapsed:  0:00:04, Remaining:  0:00:37.\n",
      "  Batch   124  of  1,250.    Elapsed:  0:00:06, Remaining:  0:00:36.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "stats = train_bern_model(\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    EPOCHS,\n",
    "    device,\n",
    "    loss_function,\n",
    "    id2label,\n",
    "    batch_schema=batch_schema,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    print_status=True,\n",
    "    is_hf_model=IS_HF_MODEL,\n",
    "    checkpoint_path=CHECKPOINT_PATH,\n",
    "    train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    test_batch_size=TEST_BATCH_SIZE,\n",
    "    only_save_core=False,\n",
    "    one_label_only=ONE_LABEL_ONLY,\n",
    "    mixed_lm_task=False,\n",
    "    mixed_lm_loss_function=nn.CrossEntropyLoss(),\n",
    "    \n",
    "    generic_output_class=True,\n",
    "    \n",
    "    #forward_args=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"labels\"],\n",
    "    #forward_args=[\"input_ids\"],\n",
    "\n",
    "    add_layers_on_stagnation=False,\n",
    "    num_layers_to_add=1,\n",
    "    add_layers_threshold=0.01, #0.005,\n",
    "    plot_k_topics=False,\n",
    "\n",
    "    batch_hack_train=True,\n",
    "    mlm_decode_n=0,#.0075,\n",
    "    tokenizer=tokenizer,\n",
    "\n",
    "    masked_lm_task=False,\n",
    "    check_run=CHECK_RUN,\n",
    "    retain_graph=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "## SST 2 test\n",
    "## [loss] / [acc/ham]\n",
    "\n",
    "# 35k\n",
    "# .61 / .79 epoch 4 ; .59 / .78 epoch 3 ; .52 / .776 epoch 2 15k pretraining, num_labels=2\n",
    "\n",
    "# .48 / .80 epoch 3\n",
    "\n",
    "\n",
    "# 10k\n",
    "# .51 / .758 epoch 2 empty\n",
    "# .57 / .778 epoch 3 empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# hf bert (empty): batch_size=6, time per epoch=6:30min, 5734MiB VRAM, 0.756 0.786 epoch 6\n",
    "# hf t5 (empty): batch_size=6, time per epoch=5:17min, 5306MiB VRAM, 0.758 0.773 epoch 5\n",
    "# hf t5 (empty) num_layers=12 num_heads=12: batch_size=3, time per epoch=11:45min, 7416MiB VRAM, 0.758 0.787 epoch 5\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
