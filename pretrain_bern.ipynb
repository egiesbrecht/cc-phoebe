{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/pushshift/cc-phoebe/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/pushshift/cc-phoebe/rotary_embeddings.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/mnt/pushshift/cc-phoebe/rotary_embeddings.py:253: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "from datasets import DatasetDict, load_dataset, Dataset, concatenate_datasets, load_from_disk\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import AdamW\n",
    "from torch import nn\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    PreTrainedTokenizer,\n",
    "    BertTokenizer, \n",
    "    RobertaTokenizer,\n",
    "    XLNetTokenizer,\n",
    "    T5Tokenizer,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "from load_set import load_set, load_moses_set\n",
    "from epoch_stats import EpochStats, print_stat_tuples\n",
    "import model_training\n",
    "from model_training import (\n",
    "    BatchBuffer, \n",
    "    mask_tokens, \n",
    "    train_bern_model, \n",
    "    preprocess_for_maskedlm, \n",
    "    preprocess_for_causallm, \n",
    "    preprocess_for_monologe, \n",
    "    preprocess_for_sparselm, \n",
    "    preprocess_for_binary_sparselm,\n",
    "    num_parameters, \n",
    "    num_trainable_parameters,\n",
    "    preprocess_for_translation,\n",
    "    preprocess_for_key_masking\n",
    ")\n",
    "\n",
    "import coin_i2C_modeling as ci2C\n",
    "import coin_i2D_modeling as ci2D\n",
    "import coin_i3A_modeling as ci3A\n",
    "import coin_i3C_modeling as ci3C\n",
    "import coin_i4_modeling as ci4\n",
    "import transformer_modeling as tm\n",
    "import coin_rnn_modeling as ciR\n",
    "import perceiver_modeling as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "REBATCH = False\n",
    "TRAIN_BATCH_SIZE = 6\n",
    "TEST_BATCH_SIZE = 6\n",
    "#BASE_PATH = \"benchmark_models/Llama_config_B3/\"\n",
    "#BASE_PATH = \"benchmark_models/ppl_play/10k_play/\"\n",
    "#BASE_PATH = \"tmp_models/ci3c_mlm_wikitext/\"\n",
    "BASE_PATH = None\n",
    "\n",
    "#BASE_PATH = \"pretrained_models/COIN-i3C_inbio_mask_no-decoder\"\n",
    "#BASE_PATH = \"tmp_models/COIN-i3C_oasst1_25k_mlm_1x2_1dec-none_no-revert_parallel_mlm-head_B6_no-shuffle_A-T_multi-query-2/\"\n",
    "\n",
    "if REBATCH:\n",
    "    if BASE_PATH[-1] == \"/\":\n",
    "        BASE_PATH = BASE_PATH[:-1]\n",
    "    BASE_PATH += \"_rebatch/\"\n",
    "DATASET_JSON_PATH = f\"{BASE_PATH}/dataset/\"\n",
    "CHECKPOINT_PATH = f\"{BASE_PATH}/model/\" if BASE_PATH is not None else None\n",
    "WORDPIECE_TOKENIZER_DIR = f\"{BASE_PATH}/wordpiece_tokenizer/\"\n",
    "BPE_TOKENIZER_DIR = f\"{BASE_PATH}/bpe_tokenizer/\"\n",
    "SENTENCE_PIECE_TOKENIZER_DIR = f\"{BASE_PATH}/sentence_piece_tokenizer/\"\n",
    "USE_CUSTOM_DATALOADER = False\n",
    "LEARNING_RATE = 4e-4\n",
    "EPS = 1e-8\n",
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE_TRAIN_DATA = True\n",
    "SHUFFLE_TEST_DATA = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAUSAL_LM = False\n",
    "ENCODE_CAUSAL_LM = False\n",
    "GROUP_TEXTS = True\n",
    "SPARSIFY = True\n",
    "MASK_TOKEN = None\n",
    "PAD_TOKEN = None\n",
    "PREFIX = None#\"Translate the following text:\"\n",
    "#PREFIX = \"Replace all of the mask-tokens: \"\n",
    "#PREFIX = \"This sentence is completely obsolete \"\n",
    "SWITCH_II_DECODER_II = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'out dir: None'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"out dir: {BASE_PATH}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VOCAB_SIZE = 30_522\n",
    "#VOCAB_SIZE = 32_000\n",
    "VOCAB_SIZE = 50257 #+ 2\n",
    "MAX_POSITION_EMBEDDINGS = 512\n",
    "IS_HF_MODEL = False\n",
    "IS_ENCODER_DECODER_MODEL = False\n",
    "EPOCH_I = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCCA_SAVE_CONFIG = ci3C.COINConfig(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "    forward_method=\"parallel\",\n",
    "    apply_decay=True,\n",
    "    num_decay_parts=1,\n",
    "    hidden_retention_act=\"relu\",\n",
    "    hidden_pos_offset=False,\n",
    "    rope_dim=16,\n",
    "    num_query_heads=1,\n",
    "\n",
    "    decoder_output=\"adaptive\",\n",
    "    revert_decoder=True,\n",
    "    decoder_schema=[1] * 4,\n",
    "    cross_encoder_schema=[1] * 4,\n",
    "    block_io_schema=None,#[[1024, 1024*4, 1024], [1024, 1024*2, 1024]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TM_CONFIG = tm.TransformerConfig(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    hidden_size=1024,\n",
    "    intermediate_size=1536,\n",
    "    num_layers=1,\n",
    "    rms_norm_eps=1e-6,\n",
    "    max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    model = tm.TransformerForCausalLM(\n",
    "        config=TM_CONFIG\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    model = tm.TransformerForMaskedLM(\n",
    "        config=TM_CONFIG\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    model = ciR.COINForCausalLM(\n",
    "        config=ciR.COINConfig(\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "            hidden_size=1024,\n",
    "            num_layers=4,\n",
    "            rms_norm_eps=1e-6\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCEIVER_CONFIG = pm.PerceiverConfig(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    hidden_size=1024,\n",
    "    intermediate_size=1536,\n",
    "    num_layers=1,\n",
    "    rms_norm_eps=1e-6,\n",
    "    max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "    num_heads=1,\n",
    "    num_kv_heads=1,\n",
    "    #conv_kernel_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    model = pm.PerceiverForCausalLM(\n",
    "        config=PERCEIVER_CONFIG\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    model = pm.PerceiverForMaskedLM(\n",
    "        config=PERCEIVER_CONFIG\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    model = ci4.COINForCausalLM(\n",
    "        config=ci4.COINConfig(\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            hidden_size=1024,\n",
    "            intermediate_size=1536,\n",
    "            forward_method=\"llama\",\n",
    "            num_layers=4,\n",
    "            max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "            rms_norm_eps=1e-6,\n",
    "            hidden_dropout_prob=0.0,\n",
    "            training_chunk_size=None,\n",
    "            inference_chunk_size=None,\n",
    "            reset_hidden_states=True,\n",
    "            apply_decay_mask=True,\n",
    "            apply_attention_mask=False,\n",
    "            apply_group_mask=False,\n",
    "            gamma=(1 - 1e-6),\n",
    "            num_heads=1,\n",
    "            num_key_value_heads=None,\n",
    "            conv_kernel_size=8,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    IS_HF_MODEL = True\n",
    "    model = transformers.LlamaForCausalLM(\n",
    "        config=transformers.LlamaConfig(\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            hidden_size=1024,\n",
    "            intermediate_size=1536,\n",
    "            num_hidden_layers=4,\n",
    "            num_attention_heads=1,\n",
    "            num_key_value_heads=1,\n",
    "            max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "            rms_norm_eps=1e-6,\n",
    "            #hidden_dropout_prob=0.0,\n",
    "            #use_cache=False,\n",
    "            #_attn_implementation=\"eager\",\n",
    "            #mlp_bias=True,\n",
    "            #attention_bias=True,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CI3C_CONFIG = ci3C.COINConfig(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    max_position_embeddings=MAX_POSITION_EMBEDDINGS,\n",
    "    hidden_size=1024,\n",
    "    forward_method=\"parallel\",\n",
    "    apply_decay=True,\n",
    "    num_decay_parts=1,\n",
    "    hidden_retention_act=\"relu\",\n",
    "    hidden_pos_offset=False,\n",
    "    rope_dim=16,\n",
    "    num_query_heads=1,\n",
    "\n",
    "    decoder_output=\"none\",\n",
    "    revert_decoder=False,\n",
    "    decoder_schema=[0] * 2,\n",
    "    cross_encoder_schema=[0] * 2,\n",
    "    experts_schema=None,#[2, 2],\n",
    "    block_io_schema=None,#[[1024, 1024*4, 1024]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    model = ci3C.COINForConditionalGeneration(\n",
    "        CI3C_CONFIG\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    model = ci3C.COINForMaskedLM(\n",
    "        CI3C_CONFIG\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    model = ci3C.COINForCausalLM(\n",
    "        CI3C_CONFIG\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    CHECKPOINT = \"tmp_models/ci3c_mlm_wikitext/\"\n",
    "    I = 5\n",
    "    tokenizer = BertTokenizer.from_pretrained(f\"{CHECKPOINT}/wordpiece_tokenizer/\")\n",
    "    model = ci3C.COINForCausalLM.from_pretrained(f\"{CHECKPOINT}/model/epoch_{I}/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128,659,584\n",
      "128,658,560\n"
     ]
    }
   ],
   "source": [
    "print(\"{:,}\\n{:,}\".format(num_parameters(model), num_trainable_parameters(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: 'None/wordpiece_tokenizer/'\n",
      "[Errno 17] File exists: 'None/bpe_tokenizer/'\n",
      "[Errno 17] File exists: 'None/sentence_piece_tokenizer/'\n",
      "[Errno 17] File exists: 'None/dataset/'\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "if BASE_PATH is not None:\n",
    "    try:\n",
    "        os.mkdir(BASE_PATH)\n",
    "    except OSError as err:\n",
    "        print(err)\n",
    "if CHECKPOINT_PATH is not None:\n",
    "    try:\n",
    "        os.mkdir(CHECKPOINT_PATH)\n",
    "    except OSError as err:\n",
    "        print(err)\n",
    "try:\n",
    "    os.mkdir(WORDPIECE_TOKENIZER_DIR)\n",
    "except OSError as err:\n",
    "    print(err)\n",
    "try:\n",
    "    os.mkdir(BPE_TOKENIZER_DIR)\n",
    "except OSError as err:\n",
    "    print(err)\n",
    "try:\n",
    "    os.mkdir(SENTENCE_PIECE_TOKENIZER_DIR)\n",
    "except OSError as err:\n",
    "    print(err)\n",
    "try:\n",
    "    os.mkdir(DATASET_JSON_PATH)\n",
    "except OSError as err:\n",
    "    print(err)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#dataset = DatasetDict({\n",
    "#    \"train\": load_dataset(\"wikitext\", name=\"wikitext-103-raw-v1\", split=\"train[0:10000]\"),\n",
    "#    \"test\":  load_dataset(\"wikitext\", name=\"wikitext-103-raw-v1\", split=\"validation[:1500]\")\n",
    "#})\n",
    "\n",
    "#dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oasst1, aaabdon, mcca, translation_mcca\n",
    "DATASET = \"wikitext_ppl\"\n",
    "#DATASET = \"wikitext_mlm\"\n",
    "\n",
    "#HF_TRAIN_ROWS = 25_000\n",
    "#HF_TRAIN_ROWS = 10_000\n",
    "HF_TRAIN_ROWS = 25_000\n",
    "HF_TRAIN_FROM = 0#10_000\n",
    "\n",
    "#HF_TEST_ROWS = 1_500\n",
    "#HF_TEST_ROWS = 1000\n",
    "HF_TEST_ROWS = -1\n",
    "HF_TEST_FROM = 0\n",
    "\n",
    "CUSTOM_BASE_DS_PATH = \"../datasets/big_AAABDON_Nmax_st200_s0_a10_tvsplit.1_no_norm/\"\n",
    "CUSTOM_DS_TO_FILE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 25000\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 4358\n",
      "})\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 1805708\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "if DATASET in (\"wikitext_ppl\", \"wikitext_mlm\"):\n",
    "    train_dataset = load_dataset(\"wikitext\", \"wikitext-103-raw-v1\", split=\"train\")\n",
    "    test_dataset = load_dataset(\"wikitext\", \"wikitext-103-raw-v1\", split=\"test\")\n",
    "    tok_dataset = concatenate_datasets([train_dataset, test_dataset])\n",
    "elif DATASET == \"slim_pajama\":\n",
    "    CACHE_DIR = \"/mnt/pushshift/slim_lajama_627B/\"\n",
    "    train_dataset = load_dataset(\"cerebras/SlimPajama-627B\", split=f\"train[{HF_TRAIN_FROM}:{HF_TRAIN_ROWS}]\", cache_dir=CACHE_DIR)\n",
    "    test_dataset = load_dataset(\"cerebras/SlimPajama-627B\", split=f\"validation[{HF_TEST_FROM}:{HF_TEST_ROWS}]\", cache_dir=CACHE_DIR)\n",
    "    tok_dataset = concatenate_datasets([train_dataset, test_dataset])\n",
    "elif DATASET == \"inbio_mask\":\n",
    "    inbio = load_set([\"INBIO.csv\"], unused_fields=(\"Synonyms,Obsolete,CUI,Semantic Types,Parents,achieves,adjacent to,affects,allocates,capable of,characteristic for,completed invasion phase,contained in,contains,contributes to,contributor,created by,decreases,decreases effort in,derives from,derives into,determines,don't use concept,editor note,enabled by,ends,ends during,ends with,enhance,facilitate,has alien range,has amount of closely related species,has amount of species,has area,has component,has decreased effort level by,has distribution,has growth,has habitat,has increased effort level by,has increased levels of,has index,has input,has invasion success likelihood,has level of,has measurement,has measurement unit label,has measurement value,has mortality,has natality,has native range,has number of individuals,has output,has part,has part structure that is capable of,has participant,has propagule pressure,has quality,has range,has recruitment,has role,has spatial occupant at some time,has specific name,has status,has value,http://data.bioontology.org/metadata/obo/part_of,http://data.bioontology.org/metadata/prefixIRI,http://data.bioontology.org/metadata/treeView,http://purl.obolibrary.org/obo/IAO_0000111,http://purl.obolibrary.org/obo/IAO_0000112,http://purl.obolibrary.org/obo/IAO_0000114,http://purl.obolibrary.org/obo/IAO_0000115,http://purl.obolibrary.org/obo/IAO_0000118,http://purl.obolibrary.org/obo/IAO_0000119,http://purl.obolibrary.org/obo/IAO_0000232,http://purl.obolibrary.org/obo/IAO_0000412,http://purl.obolibrary.org/obo/ncbitaxon#has_rank,http://purl.obolibrary.org/obo/NCIT_A8,http://purl.obolibrary.org/obo/NCIT_NHC0,http://purl.obolibrary.org/obo/NCIT_P106,http://purl.obolibrary.org/obo/NCIT_P107,http://purl.obolibrary.org/obo/NCIT_P108,http://purl.obolibrary.org/obo/NCIT_P207,http://purl.obolibrary.org/obo/NCIT_P322,http://purl.obolibrary.org/obo/NCIT_P325,http://purl.obolibrary.org/obo/NCIT_P366,http://purl.obolibrary.org/obo/OBI_0001886,http://purl.obolibrary.org/obo/RO_0001900,http://purl.org/dc/elements/1.1/source,http://purl.org/dc/terms/creator,http://www.geneontology.org/formats/oboInOwl#creation_date,http://www.geneontology.org/formats/oboInOwl#hasAlternativeId,http://www.geneontology.org/formats/oboInOwl#hasBroadSynonym,http://www.geneontology.org/formats/oboInOwl#hasDbXref,http://www.geneontology.org/formats/oboInOwl#hasExactSynonym,http://www.geneontology.org/formats/oboInOwl#hasNarrowSynonym,http://www.geneontology.org/formats/oboInOwl#hasOBONamespace,http://www.geneontology.org/formats/oboInOwl#hasRelatedSynonym,http://www.geneontology.org/formats/oboInOwl#hasSynonymType,http://www.geneontology.org/formats/oboInOwl#id,http://www.geneontology.org/formats/oboInOwl#inSubset,http://www.w3.org/2000/01/rdf-schema#comment,http://www.w3.org/2000/01/rdf-schema#label,http://www.w3.org/2002/07/owl#deprecated,http://www.w3.org/2004/02/skos/core#altLabel,http://www.w3.org/2004/02/skos/core#definition,http://www.w3.org/2004/02/skos/core#notation,https://w3id.org/inbio#_000130,https://w3id.org/inbio#_000132,increases,increases effort in,interacts with,is absent,is affected by,is against,is aggregate of,is alien range to,is characteristic of,is characterized by,is closely related to,is enemy of,is enhanced by,is growth of,is habitat of,is in invasion phase,is mortality of,is natality of,is native range to,is part of,is prey of,is range of,is recruitment of,is similar to,is status of,license,license,license,license,located in,location of,occupies spatial region at some time,occurs in,output of,overlaps,part of,participates in,produced by,produces,quality of,role of,shows changes in species trait,spatially coextensive with,surrounded by,surrounds,title,TODO,license.1,license.2,license.3\".split(\",\")))\n",
    "    bio2def = dict(zip(inbio[\"Preferred Label\"], inbio[\"Definitions\"]))\n",
    "    mask_keys = inbio[\"Preferred Label\"]\n",
    "\n",
    "    DS_TRAIN_PATH = \"datasets/abstracts_all_labels_train.csv\"\n",
    "    DS_TEST_PATH = \"datasets/abstracts_all_labels_test.csv\"\n",
    "\n",
    "    train_dataset = load_set([DS_TRAIN_PATH], unused_fields=[\"head\", \"body\", \"strlabels\"])\n",
    "    test_dataset = load_set([DS_TEST_PATH], unused_fields=[\"head\", \"body\", \"strlabels\"])\n",
    "\n",
    "    tok_dataset = concatenate_datasets([train_dataset, test_dataset])\n",
    "elif DATASET == \"mcca\":\n",
    "    train_dataset = load_moses_set({\n",
    "        \"text\": [\n",
    "            \"../datasets/multi_cc_aligned_en-de/en/x00[0-2][0-9]\",\n",
    "        ]\n",
    "    })\n",
    "    test_dataset = load_moses_set({\n",
    "        \"text\": [\n",
    "            \"../datasets/multi_cc_aligned_en-de/en/x800[0-1]\",\n",
    "        ]\n",
    "    })\n",
    "    tok_dataset = concatenate_datasets([train_dataset, test_dataset])\n",
    "elif DATASET == \"translation_mcca\":\n",
    "    train_dataset = load_moses_set({\n",
    "        \"src\": [\n",
    "            \"../datasets/multi_cc_aligned_en-de/en/x00[0-5][0-9]\",\n",
    "            \"../datasets/multi_cc_aligned_en-de/de/x00[0-5][0-9]\",\n",
    "        ],\n",
    "        \"tgt\": [\n",
    "            \"../datasets/multi_cc_aligned_en-de/de/x00[0-5][0-9]\",\n",
    "            \"../datasets/multi_cc_aligned_en-de/en/x00[0-5][0-9]\",\n",
    "        ]\n",
    "    })\n",
    "    test_dataset = load_moses_set({\n",
    "        \"src\": [\n",
    "            \"../datasets/multi_cc_aligned_en-de/en/x800[0-1]\",\n",
    "            \"../datasets/multi_cc_aligned_en-de/de/x800[0-1]\",\n",
    "        ],\n",
    "        \"tgt\": [\n",
    "            \"../datasets/multi_cc_aligned_en-de/de/x800[0-1]\",\n",
    "            \"../datasets/multi_cc_aligned_en-de/en/x800[0-1]\",\n",
    "        ]\n",
    "    })\n",
    "    tok_dataset = load_moses_set({\n",
    "        \"text\": [\n",
    "            \"../datasets/multi_cc_aligned_en-de/en/x00[0-9][0-9]\",\n",
    "            \"../datasets/multi_cc_aligned_en-de/de/x00[0-9][0-9]\",\n",
    "        ]\n",
    "    })\n",
    "elif DATASET == \"aaabdon\":\n",
    "    train_ds = [f\"{CUSTOM_BASE_DS_PATH}/train/train_00[0-{CUSTOM_DS_TO_FILE}].csv\"]\n",
    "    test_ds = [f\"{CUSTOM_BASE_DS_PATH}/validation/validation_00[0-{CUSTOM_DS_TO_FILE}].csv\"]\n",
    "    train_dataset = load_set(train_ds)#.select(list(range(HF_TRAIN_ROWS)))\n",
    "    test_dataset = load_set(test_ds)#.select(list(range(HF_TEST_ROWS)))\n",
    "    tok_dataset = load_set([f\"{CUSTOM_BASE_DS_PATH}/train/train_*.csv\"])\n",
    "elif DATASET == \"oasst1\":\n",
    "    #train_dataset = load_dataset(\"wikitext\", name=\"wikitext-103-raw-v1\", split=f\"train[0:{HF_TRAIN_ROWS}]\")\n",
    "    #test_dataset = load_dataset(\"wikitext\", name=\"wikitext-103-raw-v1\", split=f\"validation[:{HF_TEST_ROWS}]\")\n",
    "    #tok_dataset = load_dataset(\"wikitext\", name=\"wikitext-103-raw-v1\", split=\"train\")\n",
    "    \n",
    "    #train_dataset = load_dataset(\"QingyiSi/Alpaca-CoT\", split=f\"train[0:{HF_TRAIN_ROWS}]\")  .rename_column(\"instruction\", \"text\").rename_column(\"output\", \"target\")\n",
    "    #test_dataset = load_dataset(\"QingyiSi/Alpaca-CoT\", split=f\"test[0:{HF_TEST_ROWS}]\")     .rename_column(\"instruction\", \"text\").rename_column(\"output\", \"target\")\n",
    "    #tok_dataset = load_dataset(\"QingyiSi/Alpaca-CoT\")                                       .rename_column(\"instruction\", \"text\").rename_column(\"output\", \"target\")\n",
    "\n",
    "    train_dataset = load_dataset(\"OpenAssistant/oasst1\", split=\"train\").filter(lambda e: e[\"lang\"] == \"en\")\n",
    "    test_dataset = load_dataset(\"OpenAssistant/oasst1\", split=\"validation\").filter(lambda e: e[\"lang\"] == \"en\")\n",
    "    tok_dataset = load_dataset(\"OpenAssistant/oasst1\", split=\"train\").filter(lambda e: e[\"lang\"] == \"en\")\n",
    "    #train_dataset = load_from_disk(\"../datasets/oasst1/train\").filter(lambda e: e[\"lang\"] == \"en\").select(list(range(HF_TRAIN_ROWS)))\n",
    "    #test_dataset = load_from_disk(\"../datasets/oasst1/validation\").filter(lambda e: e[\"lang\"] == \"en\").select(list(range(HF_TEST_ROWS)))\n",
    "    #tok_dataset = load_from_disk(\"../datasets/oasst1/train\").filter(lambda e: e[\"lang\"] == \"en\")\n",
    "\n",
    "    #train_dataset = load_dataset(\"OpenAssistant/oasst2\", split=\"train\").filter(lambda e: e[\"lang\"] == \"en\").select(list(range(HF_TRAIN_ROWS)))\n",
    "    #test_dataset = load_dataset(\"OpenAssistant/oasst2\", split=\"validation\").filter(lambda e: e[\"lang\"] == \"en\").select(list(range(HF_TEST_ROWS)))\n",
    "\n",
    "if SHUFFLE_TRAIN_DATA:\n",
    "    print(\"shuffle\")\n",
    "    train_dataset = train_dataset.shuffle()\n",
    "if HF_TRAIN_ROWS > 0:\n",
    "    train_dataset =  train_dataset.select(list(range(HF_TRAIN_FROM, HF_TRAIN_ROWS)))\n",
    "if SHUFFLE_TEST_DATA:\n",
    "    print(\"shuffle\")\n",
    "    test_dataset = test_dataset.shuffle()\n",
    "if HF_TEST_ROWS > 0:\n",
    "    test_dataset = test_dataset.select(list(range(HF_TEST_FROM, HF_TEST_ROWS)))\n",
    "\n",
    "print(train_dataset)\n",
    "print(test_dataset)\n",
    "print(tok_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset.to_json(f\"{DATASET_JSON_PATH}/train.json\")\n",
    "#test_dataset.to_json(f\"{DATASET_JSON_PATH}/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "labels = [label for label in train_dataset.features.keys() if label not in [\"text\"]]\n",
    "id2label = {idx:label for idx, label in enumerate(labels)}\n",
    "label2id = {label:idx for idx, label in enumerate(labels)}\n",
    "print(label2id)\n",
    "print(id2label)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import ByteLevelBPETokenizer, BertWordPieceTokenizer, SentencePieceBPETokenizer, SentencePieceUnigramTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if 0:\n",
    "    #tok_dataset = load_dataset(\"wikitext\", name=\"wikitext-103-raw-v1\", split=\"train\")\n",
    "    #tok_dataset = load_dataset(\"glue\", name=\"sst2\", split=\"train\")\n",
    "    #tok_dataset = tok_dataset.rename_column(\"sentence\", \"text\")\n",
    "    \n",
    "    tokenizer = SentencePieceUnigramTokenizer()\n",
    "\n",
    "    tokenizer.train_from_iterator(\n",
    "        iterator=tok_dataset[\"text\"], \n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        #min_frequency=2,\n",
    "        show_progress=True,\n",
    "        #limit_alphabet=500,\n",
    "        special_tokens=[\n",
    "            \"<PAD>\", \n",
    "            \"<UNK>\", \n",
    "            \"<CLS>\", \n",
    "            \"<SEP>\", \n",
    "            \"<DOC>\",\n",
    "            \"<MASK>\"\n",
    "        ])\n",
    "\n",
    "    tokenizer = PreTrainedTokenizer(\n",
    "        tokenizer_object=tokenizer\n",
    "    )\n",
    "    tokenizer.save_model(SENTENCE_PIECE_TOKENIZER_DIR)\n",
    "    #assert False\n",
    "    #tokenizer = AutoTokenizer.from_pretrained(SENTENCE_PIECE_TOKENIZER_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iterator():\n",
    "    for i in range(0, len(tok_dataset), TRAIN_BATCH_SIZE):\n",
    "        yield tok_dataset[i : i + TRAIN_BATCH_SIZE][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/pushshift/cc-phoebe/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if 1:\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        \"gpt2\", \n",
    "    #    vocab_size=VOCAB_SIZE - 2,\n",
    "    #    pad_token=\"<|pad|>\",\n",
    "    #    unk_token=\"<|unk|>\",\n",
    "    #    bos_token=\"<|doc|>\",\n",
    "    #    eos_token=\"<|udoc|>\",\n",
    "    )\n",
    "    #tokenizer.eos_token_id = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    old_tokenizer = transformers.AutoTokenizer.from_pretrained(\"AdithyaSK/LLama3Tokenizer\", token=ACCESS_TOKEN)\n",
    "    tokenizer = old_tokenizer.train_new_from_iterator(batch_iterator(), vocab_size=VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if 0:\n",
    "    tokenizer = BertWordPieceTokenizer(clean_text=True, handle_chinese_chars=True,\n",
    "                                        strip_accents=True, lowercase=True)\n",
    "    #tokenizer = transformers.LlamaTokenizer()\n",
    "\n",
    "    tokenizer.train_from_iterator(iterator=tok_dataset[\"text\"], vocab_size=VOCAB_SIZE, min_frequency=2, special_tokens=[\n",
    "        \"[PAD]\", \n",
    "        \"[UNK]\", \n",
    "        \"[CLS]\", \n",
    "        \"[SEP]\", \n",
    "    #    \"[DOC]\",\n",
    "    #    \"[UDOC]\",\n",
    "        \"[MASK]\"\n",
    "    ])\n",
    "    tokenizer.save_model(WORDPIECE_TOKENIZER_DIR)\n",
    "    #assert False\n",
    "    tokenizer = BertTokenizer.from_pretrained(WORDPIECE_TOKENIZER_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "if 0:\n",
    "    tokenizer = ByteLevelBPETokenizer(lowercase=True)\n",
    "    \n",
    "    tokenizer.train_from_iterator(iterator=tok_dataset[\"text\"], vocab_size=VOCAB_SIZE, min_frequency=2, length=MAX_POSITION_EMBEDDINGS, special_tokens=[\n",
    "        \"<s>\",\n",
    "        \"<pad>\",\n",
    "        \"</s>\",\n",
    "        \"<unk>\",\n",
    "        \"<doc>\",\n",
    "        \"<mask>\",\n",
    "        \n",
    "        #\"<pad>\",\n",
    "        #\"<unk>\",\n",
    "        #\"<cls>\",\n",
    "        #\"<sep>\",\n",
    "        #\"<doc>\",\n",
    "        #\"<mask>\",\n",
    "    ])\n",
    "\n",
    "    # Save files to disk\n",
    "    tokenizer.save_model(BPE_TOKENIZER_DIR)\n",
    "    #assert False\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(BPE_TOKENIZER_DIR)\n",
    "    #tokenizer = AutoTokenizer.from_pretrained(BPE_TOKENIZER_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def encode_and_batch(dataset, tokenizer, max_position_embeddings, batch_size, shuffle=False):\n",
    "    if DATASET == \"inbio_mask\":\n",
    "        encoded = preprocess_for_key_masking(mask_keys, dataset, tokenizer, max_position_embeddings, remove_columns=dataset.column_names, to_mask=.15, chance_rand_token=.2, \n",
    "                                          group_texts=GROUP_TEXTS, pad_token=PAD_TOKEN, sparsify=SPARSIFY, prefix=PREFIX, switch_ii_decoder_ii=SWITCH_II_DECODER_II)\n",
    "    elif DATASET in (\"translation_mcca\"):\n",
    "        encoded = preprocess_for_translation(dataset, tokenizer, max_position_embeddings, source_lang=\"src\", target_lang=\"tgt\", prefix=PREFIX, num_proc=4, remove_columns=[\"src\", \"tgt\"], switch_ii_decoder_ii=SWITCH_II_DECODER_II)\n",
    "    elif DATASET in (\"wikitext_ppl\"):\n",
    "        encoded = preprocess_for_causallm(\n",
    "            dataset, \n",
    "            tokenizer, \n",
    "            block_size=MAX_POSITION_EMBEDDINGS, \n",
    "            remove_columns=dataset.column_names, \n",
    "            shift_right=False,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            doc_token_id=tokenizer.bos_token_id,\n",
    "            udoc_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    elif DATASET in (\"wikitext_mlm\"):\n",
    "        encoded = preprocess_for_maskedlm(\n",
    "            dataset, \n",
    "            tokenizer, \n",
    "            max_position_embeddings, \n",
    "            remove_columns=dataset.column_names, \n",
    "            to_mask=.15,\n",
    "            chance_rand_token=.2, \n",
    "            group_texts=GROUP_TEXTS, \n",
    "            mask_token=MASK_TOKEN, \n",
    "            pad_token=PAD_TOKEN, \n",
    "            sparsify=SPARSIFY, \n",
    "            prefix=PREFIX, \n",
    "            switch_ii_decoder_ii=False\n",
    "        )\n",
    "        \n",
    "    print(encoded)\n",
    "    batched = BatchBuffer(encoded, batch_size)\n",
    "    if shuffle:\n",
    "        batched.shuffle()\n",
    "    print(\"  finished\")\n",
    "    return batched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ''}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' = Robert Boulter = \\n'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4):   0%|          | 0/25000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4):   4%|▍         | 1000/25000 [00:00<00:05, 4040.98 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4):  20%|██        | 5000/25000 [00:00<00:01, 14709.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4):  36%|███▌      | 9000/25000 [00:00<00:00, 20076.84 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4):  52%|█████▏    | 13000/25000 [00:00<00:00, 22452.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4):  68%|██████▊   | 17000/25000 [00:00<00:00, 24214.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4):  84%|████████▍ | 21000/25000 [00:00<00:00, 26187.46 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n",
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4):  98%|█████████▊| 24500/25000 [00:01<00:00, 28379.30 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num keys: dict_keys(['input_ids', 'group_mask', 'attention_mask'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=4): 100%|██████████| 25000/25000 [00:01<00:00, 21366.92 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'group_mask', 'attention_mask', 'decoder_input_ids', 'labels'],\n",
      "    num_rows: 3254\n",
      "})\n",
      "  finished\n",
      "Dataset({\n",
      "    features: ['input_ids', 'group_mask', 'attention_mask', 'decoder_input_ids', 'labels'],\n",
      "    num_rows: 557\n",
      "})\n",
      "  finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "train_loader_call = lambda: encode_and_batch(train_dataset, tokenizer, MAX_POSITION_EMBEDDINGS, TRAIN_BATCH_SIZE, True)\n",
    "test_loader_call = lambda: encode_and_batch(test_dataset, tokenizer, MAX_POSITION_EMBEDDINGS, TEST_BATCH_SIZE)\n",
    "\n",
    "if not REBATCH:\n",
    "    train_dataloader = train_loader_call()\n",
    "    test_dataloader = test_loader_call()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 796,\n",
       " 5199,\n",
       " 347,\n",
       " 2852,\n",
       " 353,\n",
       " 796,\n",
       " 220,\n",
       " 198,\n",
       " 4,\n",
       " 4,\n",
       " 5199,\n",
       " 347,\n",
       " 2852,\n",
       " 353,\n",
       " 318,\n",
       " 281,\n",
       " 3594,\n",
       " 2646,\n",
       " 837,\n",
       " 5581,\n",
       " 290,\n",
       " 21421,\n",
       " 8674,\n",
       " 764,\n",
       " 679,\n",
       " 550,\n",
       " 257,\n",
       " 8319,\n",
       " 2488,\n",
       " 12,\n",
       " 31,\n",
       " 20495,\n",
       " 2597,\n",
       " 319,\n",
       " 262,\n",
       " 5581,\n",
       " 2168,\n",
       " 383,\n",
       " 3941,\n",
       " 287,\n",
       " 4751,\n",
       " 764,\n",
       " 770,\n",
       " 373,\n",
       " 3940,\n",
       " 416,\n",
       " 257,\n",
       " 20495,\n",
       " 2597,\n",
       " 287,\n",
       " 262,\n",
       " 711,\n",
       " 2332,\n",
       " 684,\n",
       " 3194,\n",
       " 416,\n",
       " 11288,\n",
       " 37072,\n",
       " 837,\n",
       " 543,\n",
       " 373,\n",
       " 6157,\n",
       " 287,\n",
       " 5878,\n",
       " 379,\n",
       " 262,\n",
       " 8111,\n",
       " 3078,\n",
       " 15752,\n",
       " 764,\n",
       " 679,\n",
       " 550,\n",
       " 257,\n",
       " 8319,\n",
       " 2597,\n",
       " 287,\n",
       " 262,\n",
       " 5581,\n",
       " 2168,\n",
       " 8974,\n",
       " 1757,\n",
       " 1024,\n",
       " 276,\n",
       " 287,\n",
       " 6244,\n",
       " 764,\n",
       " 554,\n",
       " 5472,\n",
       " 347,\n",
       " 2852,\n",
       " 353,\n",
       " 11406,\n",
       " 257,\n",
       " 2597,\n",
       " 355,\n",
       " 366,\n",
       " 13854,\n",
       " 366,\n",
       " 287,\n",
       " 262,\n",
       " 4471,\n",
       " 366,\n",
       " 29345,\n",
       " 705,\n",
       " 82,\n",
       " 8362,\n",
       " 366,\n",
       " 286,\n",
       " 262,\n",
       " 5581,\n",
       " 2168,\n",
       " 383,\n",
       " 5882,\n",
       " 31623,\n",
       " 2162,\n",
       " 339,\n",
       " 31636,\n",
       " 7848,\n",
       " 10544,\n",
       " 2940,\n",
       " 13535,\n",
       " 290,\n",
       " 20893,\n",
       " 12806,\n",
       " 72,\n",
       " 764,\n",
       " 679,\n",
       " 373,\n",
       " 3350,\n",
       " 287,\n",
       " 262,\n",
       " 5075,\n",
       " 21421,\n",
       " 32260,\n",
       " 286,\n",
       " 262,\n",
       " 14576,\n",
       " 39616,\n",
       " 711,\n",
       " 21673,\n",
       " 22384,\n",
       " 837,\n",
       " 543,\n",
       " 373,\n",
       " 6157,\n",
       " 379,\n",
       " 262,\n",
       " 25331,\n",
       " 15752,\n",
       " 287,\n",
       " 42125,\n",
       " 290,\n",
       " 262,\n",
       " 6065,\n",
       " 959,\n",
       " 24777,\n",
       " 19239,\n",
       " 287,\n",
       " 3576,\n",
       " 764,\n",
       " 679,\n",
       " 373,\n",
       " 7924,\n",
       " 416,\n",
       " 1757,\n",
       " 40928,\n",
       " 290,\n",
       " 31636,\n",
       " 7848,\n",
       " 3932,\n",
       " 854,\n",
       " 680,\n",
       " 707,\n",
       " 837,\n",
       " 24379,\n",
       " 1168,\n",
       " 7056,\n",
       " 837,\n",
       " 5850,\n",
       " 8758,\n",
       " 837,\n",
       " 28059,\n",
       " 13709,\n",
       " 411,\n",
       " 837,\n",
       " 35331,\n",
       " 36442,\n",
       " 290,\n",
       " 36401,\n",
       " 4789,\n",
       " 764,\n",
       " 220,\n",
       " 198,\n",
       " 4,\n",
       " 554,\n",
       " 4793,\n",
       " 837,\n",
       " 347,\n",
       " 2852,\n",
       " 353,\n",
       " 31636,\n",
       " 7848,\n",
       " 854,\n",
       " 680,\n",
       " 707,\n",
       " 287,\n",
       " 262,\n",
       " 711,\n",
       " 47002,\n",
       " 3194,\n",
       " 416,\n",
       " 2940,\n",
       " 12552,\n",
       " 12639,\n",
       " 764,\n",
       " 679,\n",
       " 4120,\n",
       " 319,\n",
       " 257,\n",
       " 4793,\n",
       " 4471,\n",
       " 286,\n",
       " 262,\n",
       " 5581,\n",
       " 2168,\n",
       " 837,\n",
       " 28274,\n",
       " 837,\n",
       " 3940,\n",
       " 416,\n",
       " 257,\n",
       " 2597,\n",
       " 287,\n",
       " 262,\n",
       " 4343,\n",
       " 21421,\n",
       " 3227,\n",
       " 286,\n",
       " 1374,\n",
       " 284,\n",
       " 19739,\n",
       " 7924,\n",
       " 416,\n",
       " 22568,\n",
       " 494,\n",
       " 371,\n",
       " 49003,\n",
       " 764,\n",
       " 1374,\n",
       " 284,\n",
       " 19739,\n",
       " 373,\n",
       " 6157,\n",
       " 379,\n",
       " 5511,\n",
       " 15752,\n",
       " 287,\n",
       " 262,\n",
       " 3576,\n",
       " 48114,\n",
       " 286,\n",
       " 4345,\n",
       " 11056,\n",
       " 22947,\n",
       " 290,\n",
       " 28040,\n",
       " 2763,\n",
       " 764,\n",
       " 347,\n",
       " 2852,\n",
       " 353,\n",
       " 31636,\n",
       " 287,\n",
       " 734,\n",
       " 7328,\n",
       " 287,\n",
       " 3648,\n",
       " 837,\n",
       " 47743,\n",
       " 3851,\n",
       " 13001,\n",
       " 416,\n",
       " 26479,\n",
       " 6342,\n",
       " 1004,\n",
       " 756,\n",
       " 72,\n",
       " 837,\n",
       " 290,\n",
       " 43823,\n",
       " 24265,\n",
       " 7924,\n",
       " 416,\n",
       " 440,\n",
       " 12810,\n",
       " 42603,\n",
       " 764,\n",
       " 554,\n",
       " 1737,\n",
       " 3648,\n",
       " 837,\n",
       " 347,\n",
       " 2852,\n",
       " 353,\n",
       " 925,\n",
       " 257,\n",
       " 8319,\n",
       " 5585,\n",
       " 319,\n",
       " 257,\n",
       " 734,\n",
       " 2488,\n",
       " 12,\n",
       " 31,\n",
       " 636,\n",
       " 4471,\n",
       " 10389,\n",
       " 286,\n",
       " 262,\n",
       " 5581,\n",
       " 2168,\n",
       " 370,\n",
       " 868,\n",
       " 262,\n",
       " 5542,\n",
       " 837,\n",
       " 3940,\n",
       " 416,\n",
       " 281,\n",
       " 5585,\n",
       " 319,\n",
       " 262,\n",
       " 5581,\n",
       " 2168,\n",
       " 45998,\n",
       " 287,\n",
       " 3389,\n",
       " 3648,\n",
       " 764,\n",
       " 679,\n",
       " 550,\n",
       " 257,\n",
       " 24824,\n",
       " 2597,\n",
       " 287,\n",
       " 3478,\n",
       " 8640,\n",
       " 286,\n",
       " 262,\n",
       " 5581,\n",
       " 2168,\n",
       " 43508,\n",
       " 774,\n",
       " 287,\n",
       " 3050,\n",
       " 837,\n",
       " 355,\n",
       " 366,\n",
       " 39717,\n",
       " 261,\n",
       " 31942,\n",
       " 366,\n",
       " 764,\n",
       " 347,\n",
       " 2852,\n",
       " 353,\n",
       " 31636,\n",
       " 287,\n",
       " 262,\n",
       " 2813,\n",
       " 2646,\n",
       " 12185,\n",
       " 30216,\n",
       " 7924,\n",
       " 416,\n",
       " 6342,\n",
       " 1004,\n",
       " 756,\n",
       " 72,\n",
       " 764,\n",
       " 220,\n",
       " 198,\n",
       " 4,\n",
       " 4,\n",
       " 796,\n",
       " 796,\n",
       " 32619,\n",
       " 796,\n",
       " 796,\n",
       " 220,\n",
       " 198,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 796,\n",
       " 796,\n",
       " 796,\n",
       " 4751,\n",
       " 784,\n",
       " 5075,\n",
       " 796,\n",
       " 796,\n",
       " 796,\n",
       " 220,\n",
       " 198,\n",
       " 4,\n",
       " 4,\n",
       " 554,\n",
       " 4751,\n",
       " 347,\n",
       " 2852,\n",
       " 353,\n",
       " 550,\n",
       " 257,\n",
       " 8319,\n",
       " 2488,\n",
       " 12,\n",
       " 31,\n",
       " 20495,\n",
       " 2597,\n",
       " 319,\n",
       " 262,\n",
       " 5581,\n",
       " 2168,\n",
       " 383,\n",
       " 3941,\n",
       " 2162,\n",
       " 339,\n",
       " 19152,\n",
       " 366,\n",
       " 4746,\n",
       " 2547,\n",
       " 563,\n",
       " 366,\n",
       " 287,\n",
       " 262,\n",
       " 4471,\n",
       " 837,\n",
       " 366,\n",
       " 554,\n",
       " 19978,\n",
       " 22237,\n",
       " 366,\n",
       " 764,\n",
       " 347,\n",
       " 2852,\n",
       " 353,\n",
       " 31636,\n",
       " 355,\n",
       " 366,\n",
       " 4746,\n",
       " 366,\n",
       " 287,\n",
       " 262,\n",
       " 711,\n",
       " 2332,\n",
       " 684,\n",
       " 3194,\n",
       " 416,\n",
       " 11288,\n",
       " 37072,\n",
       " 837,\n",
       " 543,\n",
       " 373,\n",
       " 6157,\n",
       " 287,\n",
       " 5878,\n",
       " 379,\n",
       " 262,\n",
       " 8111,\n",
       " 3078,\n",
       " 15752,\n",
       " 764,\n",
       " 317,\n",
       " 2423,\n",
       " 286,\n",
       " 347,\n",
       " 2852,\n",
       " 353,\n",
       " 705,\n",
       " 82,\n",
       " 2854,\n",
       " 287,\n",
       " 383,\n",
       " 13362,\n",
       " 319,\n",
       " 3502,\n",
       " 3417,\n",
       " 683,\n",
       " 355,\n",
       " 366,\n",
       " 33437,\n",
       " 39579,\n",
       " 366,\n",
       " 287,\n",
       " 262,\n",
       " 2597,\n",
       " 837,\n",
       " 290,\n",
       " 339,\n",
       " 2722,\n",
       " 4688,\n",
       " 8088,\n",
       " 287,\n",
       " 383,\n",
       " 18277,\n",
       " 837,\n",
       " 290,\n",
       " 31867,\n",
       " 8997,\n",
       " 764]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader.ds[0][\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#encoded_train_dataset = preprocess_for_maskedlm(dataset, tokenizer, MAX_POSITION_EMBEDDINGS, remove_columns=train_dataset.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#train_dataloader = BatchBuffer(encoded_dataset[\"train\"], BATCH_SIZE).shuffle()\n",
    "#test_dataloader = BatchBuffer(encoded_dataset[\"test\"], BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#batch_schema = list(encoded_dataset[\"train\"].features.keys())\n",
    "#batch_schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def count_item(inp, item):\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for n in inp:\n",
    "        for r in n:\n",
    "            i = r\n",
    "            if not i < 4:\n",
    "                total += 1\n",
    "            if i == item:\n",
    "                count += 1\n",
    "            #if i != 0 and i != item:\n",
    "            #    print(i)\n",
    "    return f\"{count} / {total} ; {count/total}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.mask_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masked tokens [input_ids]: 0 / 1666048 ; 0.0\n",
      "masked tokens [labels]: 0 / 285184 ; 0.0\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "print(\"masked tokens [input_ids]:\", count_item(train_dataloader.ds[\"input_ids\"], tokenizer.mask_token_id))\n",
    "print(\"masked tokens [labels]:\", count_item(test_dataloader.ds[\"labels\"], tokenizer.mask_token_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, eps=EPS)\n",
    "\n",
    "total_steps = len(train_dataset) / TRAIN_BATCH_SIZE * EPOCHS\n",
    "warmup_steps = math.ceil(total_steps * 0.05)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=warmup_steps,\n",
    "                                            num_training_steps=total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "loss_function = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'group_mask', 'attention_mask', 'decoder_input_ids', 'labels']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "train_dataloader.schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerceiverForCausalLM(\n",
       "  (model): PerceiverModel(\n",
       "    (embeddings): PerceiverEmbeddings(\n",
       "      (word_embeddings): Embedding(50257, 1024, padding_idx=0)\n",
       "    )\n",
       "    (model): PerceiverEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): PerceiverLayer(\n",
       "          (cross_attn): PCI5Attention(\n",
       "            (softmax): PartialSoftmax()\n",
       "            (Q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (K_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (V_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (rope): RotaryEmbedding()\n",
       "            (fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (cross_rms): RMSNorm()\n",
       "          (latent_rms): RMSNorm()\n",
       "          (glu_rms): RMSNorm()\n",
       "          (glu): GLU(\n",
       "            (fi): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (fc): Linear(in_features=1536, out_features=1024, bias=True)\n",
       "            (act): SiLU()\n",
       "          )\n",
       "          (gru): cGRU(\n",
       "            (fz): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (uz): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (fr): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (ur): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (fh): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (uh): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (sigmoid): Sigmoid()\n",
       "            (act): SiLU()\n",
       "          )\n",
       "          (in_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (cross_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (res_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (latents): ModuleList()\n",
       "          (out_attn): PCI5Attention(\n",
       "            (softmax): PartialSoftmax()\n",
       "            (Q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (K_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (V_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (rope): RotaryEmbedding()\n",
       "            (fc): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_rms): RMSNorm()\n",
       "          (conv): CausalConv1d()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(threshold=5_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 25 ========\n",
      "\n",
      "Generated batch schema as ['input_ids', 'group_mask', 'attention_mask', 'decoder_input_ids', 'labels']\n",
      "\n",
      "Training...\n",
      "  Batch    10  of    542.    Elapsed:  0:00:06, Remaining:  0:05:19.\n",
      "  Batch    20  of    542.    Elapsed:  0:00:11, Remaining:  0:05:13.\n",
      "  Batch    30  of    542.    Elapsed:  0:00:17, Remaining:  0:05:07.\n",
      "  Batch    40  of    542.    Elapsed:  0:00:23, Remaining:  0:05:01.\n",
      "  Batch    50  of    542.    Elapsed:  0:00:28, Remaining:  0:04:55.\n",
      "  Batch    60  of    542.    Elapsed:  0:00:34, Remaining:  0:04:49.\n",
      "  Batch    70  of    542.    Elapsed:  0:00:39, Remaining:  0:04:43.\n",
      "  Batch    80  of    542.    Elapsed:  0:00:45, Remaining:  0:04:37.\n",
      "  Batch    90  of    542.    Elapsed:  0:00:51, Remaining:  0:04:31.\n",
      "  Batch   100  of    542.    Elapsed:  0:00:56, Remaining:  0:04:25.\n",
      "  Batch   110  of    542.    Elapsed:  0:01:02, Remaining:  0:04:19.\n",
      "  Batch   120  of    542.    Elapsed:  0:01:07, Remaining:  0:04:13.\n",
      "  Batch   130  of    542.    Elapsed:  0:01:13, Remaining:  0:04:07.\n",
      "  Batch   140  of    542.    Elapsed:  0:01:19, Remaining:  0:04:01.\n",
      "  Batch   150  of    542.    Elapsed:  0:01:24, Remaining:  0:03:55.\n",
      "  Batch   160  of    542.    Elapsed:  0:01:30, Remaining:  0:03:49.\n",
      "  Batch   170  of    542.    Elapsed:  0:01:35, Remaining:  0:03:43.\n",
      "  Batch   180  of    542.    Elapsed:  0:01:41, Remaining:  0:03:37.\n",
      "  Batch   190  of    542.    Elapsed:  0:01:47, Remaining:  0:03:31.\n",
      "  Batch   200  of    542.    Elapsed:  0:01:52, Remaining:  0:03:25.\n",
      "  Batch   210  of    542.    Elapsed:  0:01:58, Remaining:  0:03:19.\n",
      "  Batch   220  of    542.    Elapsed:  0:02:04, Remaining:  0:03:13.\n",
      "  Batch   230  of    542.    Elapsed:  0:02:09, Remaining:  0:03:07.\n",
      "  Batch   240  of    542.    Elapsed:  0:02:15, Remaining:  0:03:01.\n",
      "  Batch   250  of    542.    Elapsed:  0:02:20, Remaining:  0:02:55.\n",
      "  Batch   260  of    542.    Elapsed:  0:02:26, Remaining:  0:02:49.\n",
      "  Batch   270  of    542.    Elapsed:  0:02:31, Remaining:  0:02:43.\n",
      "  Batch   280  of    542.    Elapsed:  0:02:37, Remaining:  0:02:37.\n",
      "  Batch   290  of    542.    Elapsed:  0:02:43, Remaining:  0:02:31.\n",
      "  Batch   300  of    542.    Elapsed:  0:02:48, Remaining:  0:02:25.\n",
      "  Batch   310  of    542.    Elapsed:  0:02:54, Remaining:  0:02:19.\n",
      "  Batch   320  of    542.    Elapsed:  0:03:00, Remaining:  0:02:13.\n",
      "  Batch   330  of    542.    Elapsed:  0:03:05, Remaining:  0:02:07.\n",
      "  Batch   340  of    542.    Elapsed:  0:03:11, Remaining:  0:02:01.\n",
      "  Batch   350  of    542.    Elapsed:  0:03:16, Remaining:  0:01:55.\n",
      "  Batch   360  of    542.    Elapsed:  0:03:22, Remaining:  0:01:49.\n",
      "  Batch   370  of    542.    Elapsed:  0:03:28, Remaining:  0:01:43.\n",
      "  Batch   380  of    542.    Elapsed:  0:03:33, Remaining:  0:01:37.\n",
      "  Batch   390  of    542.    Elapsed:  0:03:39, Remaining:  0:01:31.\n",
      "  Batch   400  of    542.    Elapsed:  0:03:44, Remaining:  0:01:25.\n",
      "  Batch   410  of    542.    Elapsed:  0:03:50, Remaining:  0:01:19.\n",
      "  Batch   420  of    542.    Elapsed:  0:03:56, Remaining:  0:01:13.\n",
      "  Batch   430  of    542.    Elapsed:  0:04:01, Remaining:  0:01:07.\n",
      "  Batch   440  of    542.    Elapsed:  0:04:07, Remaining:  0:01:01.\n",
      "  Batch   450  of    542.    Elapsed:  0:04:13, Remaining:  0:00:55.\n",
      "  Batch   460  of    542.    Elapsed:  0:04:18, Remaining:  0:00:49.\n",
      "  Batch   470  of    542.    Elapsed:  0:04:24, Remaining:  0:00:43.\n",
      "  Batch   480  of    542.    Elapsed:  0:04:30, Remaining:  0:00:37.\n",
      "  Batch   490  of    542.    Elapsed:  0:04:35, Remaining:  0:00:31.\n",
      "  Batch   500  of    542.    Elapsed:  0:04:41, Remaining:  0:00:25.\n",
      "  Batch   510  of    542.    Elapsed:  0:04:46, Remaining:  0:00:19.\n",
      "  Batch   520  of    542.    Elapsed:  0:04:52, Remaining:  0:00:13.\n",
      "  Batch   530  of    542.    Elapsed:  0:04:58, Remaining:  0:00:07.\n",
      "  Batch   540  of    542.    Elapsed:  0:05:03, Remaining:  0:00:01.\n",
      "\n",
      "  Average training scores:\n",
      "    loss: 7.814823688176285\n",
      "  Training epoch took: 0:05:04\n",
      "\n",
      "Running Test 1 ...\n",
      "  Average testing scores:\n",
      "    loss: 6.684985798338185\n",
      "    perplexity: 832.0493623342264\n",
      "  Testing took: 0:00:40\n",
      "\n",
      "======== Epoch 2 / 25 ========\n",
      "\n",
      "Training...\n",
      "  Batch    10  of    542.    Elapsed:  0:00:06, Remaining:  0:05:19.\n",
      "  Batch    20  of    542.    Elapsed:  0:00:11, Remaining:  0:05:13.\n",
      "  Batch    30  of    542.    Elapsed:  0:00:17, Remaining:  0:05:07.\n",
      "  Batch    40  of    542.    Elapsed:  0:00:22, Remaining:  0:05:01.\n",
      "  Batch    50  of    542.    Elapsed:  0:00:28, Remaining:  0:04:55.\n",
      "  Batch    60  of    542.    Elapsed:  0:00:34, Remaining:  0:04:49.\n",
      "  Batch    70  of    542.    Elapsed:  0:00:39, Remaining:  0:04:43.\n",
      "  Batch    80  of    542.    Elapsed:  0:00:45, Remaining:  0:04:37.\n",
      "  Batch    90  of    542.    Elapsed:  0:00:50, Remaining:  0:04:31.\n",
      "  Batch   100  of    542.    Elapsed:  0:00:56, Remaining:  0:04:25.\n",
      "  Batch   110  of    542.    Elapsed:  0:01:02, Remaining:  0:04:19.\n",
      "  Batch   120  of    542.    Elapsed:  0:01:07, Remaining:  0:04:13.\n",
      "  Batch   130  of    542.    Elapsed:  0:01:13, Remaining:  0:04:07.\n",
      "  Batch   140  of    542.    Elapsed:  0:01:18, Remaining:  0:04:01.\n",
      "  Batch   150  of    542.    Elapsed:  0:01:24, Remaining:  0:03:55.\n",
      "  Batch   160  of    542.    Elapsed:  0:01:29, Remaining:  0:03:49.\n",
      "  Batch   170  of    542.    Elapsed:  0:01:35, Remaining:  0:03:43.\n",
      "  Batch   180  of    542.    Elapsed:  0:01:41, Remaining:  0:03:37.\n",
      "  Batch   190  of    542.    Elapsed:  0:01:47, Remaining:  0:03:31.\n",
      "  Batch   200  of    542.    Elapsed:  0:01:52, Remaining:  0:03:25.\n",
      "  Batch   210  of    542.    Elapsed:  0:01:58, Remaining:  0:03:19.\n",
      "  Batch   220  of    542.    Elapsed:  0:02:04, Remaining:  0:03:13.\n",
      "  Batch   230  of    542.    Elapsed:  0:02:09, Remaining:  0:03:07.\n",
      "  Batch   240  of    542.    Elapsed:  0:02:15, Remaining:  0:03:01.\n",
      "  Batch   250  of    542.    Elapsed:  0:02:20, Remaining:  0:02:55.\n",
      "  Batch   260  of    542.    Elapsed:  0:02:26, Remaining:  0:02:49.\n",
      "  Batch   270  of    542.    Elapsed:  0:02:32, Remaining:  0:02:43.\n",
      "  Batch   280  of    542.    Elapsed:  0:02:37, Remaining:  0:02:37.\n",
      "  Batch   290  of    542.    Elapsed:  0:02:43, Remaining:  0:02:31.\n",
      "  Batch   300  of    542.    Elapsed:  0:02:48, Remaining:  0:02:25.\n",
      "  Batch   310  of    542.    Elapsed:  0:02:54, Remaining:  0:02:19.\n",
      "  Batch   320  of    542.    Elapsed:  0:03:00, Remaining:  0:02:13.\n",
      "  Batch   330  of    542.    Elapsed:  0:03:05, Remaining:  0:02:07.\n",
      "  Batch   340  of    542.    Elapsed:  0:03:11, Remaining:  0:02:01.\n",
      "  Batch   350  of    542.    Elapsed:  0:03:17, Remaining:  0:01:55.\n",
      "  Batch   360  of    542.    Elapsed:  0:03:22, Remaining:  0:01:49.\n",
      "  Batch   370  of    542.    Elapsed:  0:03:28, Remaining:  0:01:43.\n",
      "  Batch   380  of    542.    Elapsed:  0:03:33, Remaining:  0:01:37.\n",
      "  Batch   390  of    542.    Elapsed:  0:03:39, Remaining:  0:01:31.\n",
      "  Batch   400  of    542.    Elapsed:  0:03:45, Remaining:  0:01:25.\n",
      "  Batch   410  of    542.    Elapsed:  0:03:50, Remaining:  0:01:19.\n",
      "  Batch   420  of    542.    Elapsed:  0:03:56, Remaining:  0:01:13.\n",
      "  Batch   430  of    542.    Elapsed:  0:04:02, Remaining:  0:01:07.\n",
      "  Batch   440  of    542.    Elapsed:  0:04:07, Remaining:  0:01:01.\n",
      "  Batch   450  of    542.    Elapsed:  0:04:13, Remaining:  0:00:55.\n",
      "  Batch   460  of    542.    Elapsed:  0:04:18, Remaining:  0:00:49.\n",
      "  Batch   470  of    542.    Elapsed:  0:04:24, Remaining:  0:00:43.\n",
      "  Batch   480  of    542.    Elapsed:  0:04:29, Remaining:  0:00:37.\n",
      "  Batch   490  of    542.    Elapsed:  0:04:35, Remaining:  0:00:31.\n",
      "  Batch   500  of    542.    Elapsed:  0:04:41, Remaining:  0:00:25.\n",
      "  Batch   510  of    542.    Elapsed:  0:04:46, Remaining:  0:00:19.\n",
      "  Batch   520  of    542.    Elapsed:  0:04:52, Remaining:  0:00:13.\n",
      "  Batch   530  of    542.    Elapsed:  0:04:57, Remaining:  0:00:07.\n",
      "  Batch   540  of    542.    Elapsed:  0:05:03, Remaining:  0:00:01.\n",
      "\n",
      "  Average training scores:\n",
      "    loss: nan\n",
      "  Training epoch took: 0:05:04\n",
      "\n",
      "Running Test 1 ...\n",
      "  Average testing scores:\n",
      "    loss: nan\n",
      "    perplexity: nan\n",
      "  Testing took: 0:00:40\n",
      "\n",
      "======== Epoch 3 / 25 ========\n",
      "\n",
      "Training...\n",
      "  Batch    10  of    542.    Elapsed:  0:00:06, Remaining:  0:05:19.\n",
      "  Batch    20  of    542.    Elapsed:  0:00:11, Remaining:  0:05:13.\n",
      "  Batch    30  of    542.    Elapsed:  0:00:17, Remaining:  0:05:07.\n",
      "  Batch    40  of    542.    Elapsed:  0:00:22, Remaining:  0:05:01.\n",
      "  Batch    50  of    542.    Elapsed:  0:00:28, Remaining:  0:04:55.\n",
      "  Batch    60  of    542.    Elapsed:  0:00:33, Remaining:  0:04:49.\n",
      "  Batch    70  of    542.    Elapsed:  0:00:39, Remaining:  0:04:43.\n",
      "  Batch    80  of    542.    Elapsed:  0:00:45, Remaining:  0:04:37.\n",
      "  Batch    90  of    542.    Elapsed:  0:00:50, Remaining:  0:04:31.\n",
      "  Batch   100  of    542.    Elapsed:  0:00:56, Remaining:  0:04:25.\n",
      "  Batch   110  of    542.    Elapsed:  0:01:01, Remaining:  0:04:19.\n",
      "  Batch   120  of    542.    Elapsed:  0:01:07, Remaining:  0:04:13.\n",
      "  Batch   130  of    542.    Elapsed:  0:01:12, Remaining:  0:04:07.\n",
      "  Batch   140  of    542.    Elapsed:  0:01:18, Remaining:  0:04:01.\n",
      "  Batch   150  of    542.    Elapsed:  0:01:24, Remaining:  0:03:55.\n",
      "  Batch   160  of    542.    Elapsed:  0:01:29, Remaining:  0:03:49.\n",
      "  Batch   170  of    542.    Elapsed:  0:01:35, Remaining:  0:03:43.\n",
      "  Batch   180  of    542.    Elapsed:  0:01:40, Remaining:  0:03:37.\n",
      "  Batch   190  of    542.    Elapsed:  0:01:46, Remaining:  0:03:31.\n",
      "  Batch   200  of    542.    Elapsed:  0:01:52, Remaining:  0:03:25.\n",
      "  Batch   210  of    542.    Elapsed:  0:01:57, Remaining:  0:03:19.\n",
      "  Batch   220  of    542.    Elapsed:  0:02:03, Remaining:  0:03:13.\n",
      "  Batch   230  of    542.    Elapsed:  0:02:08, Remaining:  0:03:07.\n",
      "  Batch   240  of    542.    Elapsed:  0:02:14, Remaining:  0:03:01.\n",
      "  Batch   250  of    542.    Elapsed:  0:02:20, Remaining:  0:02:55.\n",
      "  Batch   260  of    542.    Elapsed:  0:02:25, Remaining:  0:02:49.\n",
      "  Batch   270  of    542.    Elapsed:  0:02:31, Remaining:  0:02:43.\n",
      "  Batch   280  of    542.    Elapsed:  0:02:36, Remaining:  0:02:37.\n",
      "  Batch   290  of    542.    Elapsed:  0:02:42, Remaining:  0:02:31.\n",
      "  Batch   300  of    542.    Elapsed:  0:02:48, Remaining:  0:02:25.\n",
      "  Batch   310  of    542.    Elapsed:  0:02:53, Remaining:  0:02:19.\n",
      "  Batch   320  of    542.    Elapsed:  0:02:59, Remaining:  0:02:13.\n",
      "  Batch   330  of    542.    Elapsed:  0:03:04, Remaining:  0:02:07.\n",
      "  Batch   340  of    542.    Elapsed:  0:03:10, Remaining:  0:02:01.\n",
      "  Batch   350  of    542.    Elapsed:  0:03:15, Remaining:  0:01:55.\n",
      "  Batch   360  of    542.    Elapsed:  0:03:21, Remaining:  0:01:49.\n",
      "  Batch   370  of    542.    Elapsed:  0:03:27, Remaining:  0:01:43.\n",
      "  Batch   380  of    542.    Elapsed:  0:03:32, Remaining:  0:01:37.\n",
      "  Batch   390  of    542.    Elapsed:  0:03:38, Remaining:  0:01:31.\n",
      "  Batch   400  of    542.    Elapsed:  0:03:44, Remaining:  0:01:25.\n",
      "  Batch   410  of    542.    Elapsed:  0:03:49, Remaining:  0:01:19.\n",
      "  Batch   420  of    542.    Elapsed:  0:03:55, Remaining:  0:01:13.\n",
      "  Batch   430  of    542.    Elapsed:  0:04:00, Remaining:  0:01:07.\n",
      "  Batch   440  of    542.    Elapsed:  0:04:06, Remaining:  0:01:01.\n",
      "  Batch   450  of    542.    Elapsed:  0:04:12, Remaining:  0:00:55.\n",
      "  Batch   460  of    542.    Elapsed:  0:04:17, Remaining:  0:00:49.\n",
      "  Batch   470  of    542.    Elapsed:  0:04:23, Remaining:  0:00:43.\n",
      "  Batch   480  of    542.    Elapsed:  0:04:28, Remaining:  0:00:37.\n",
      "  Batch   490  of    542.    Elapsed:  0:04:34, Remaining:  0:00:31.\n",
      "  Batch   500  of    542.    Elapsed:  0:04:40, Remaining:  0:00:25.\n"
     ]
    }
   ],
   "source": [
    "stats = train_bern_model(\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    EPOCHS,\n",
    "    #train_dataloader,\n",
    "    #test_dataloader,\n",
    "    #batch_schema,\n",
    "    device,\n",
    "    loss_function,\n",
    "    id2label,\n",
    "    train_dataloader=train_dataloader if not REBATCH else None,\n",
    "    test_dataloader=test_dataloader if not REBATCH else None,\n",
    "    create_train_dataloader=train_loader_call if REBATCH else None,\n",
    "    create_test_dataloader=test_loader_call if REBATCH else None,\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    print_status=True,\n",
    "    is_hf_model=IS_HF_MODEL,\n",
    "    checkpoint_path=CHECKPOINT_PATH,\n",
    "    train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    test_batch_size=TEST_BATCH_SIZE,\n",
    "    only_save_core=False,\n",
    "    epoch_i=EPOCH_I,\n",
    "    is_encoder_decoder_model=IS_ENCODER_DECODER_MODEL,\n",
    "    causal_lm=CAUSAL_LM,\n",
    "\n",
    "    forward_args=[\"input_ids\", \"attention_mask\", \"labels\"],\n",
    "    #forward_args=[\"input_ids\", \"decoder_input_ids\", \"group_mask\", \"labels\"],\n",
    "\n",
    "    masked_lm_task=True,\n",
    "    electra_task=False,\n",
    "    mlm_decode_n=0,\n",
    "    #mlm_decode_n=.0075,\n",
    "    #mlm_decode_n=.1,\n",
    "    mlm_decode_max_chars=200,\n",
    "    tokenizer=tokenizer,\n",
    "\n",
    "    dump_coin_regions=False,\n",
    "    generic_output_class=True,\n",
    "    #coin_region_lambda=lambda model: model.coin.core.regions\n",
    "\n",
    "    evaluate_autoregressively=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_stat_tuples(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
